---
title: "Model-Level Inference"
date: "`r Sys.Date()`"
header-includes:
   - \usepackage{xcolor}
   - \definecolor{umn}{HTML}{FF2D21}
   - \definecolor{myorange}{HTML}{EA6153}
   - \usepackage[framemethod=tikz]{mdframed}
   - \usepackage{graphicx}
   - \usepackage{rotating}
   - \usepackage{booktabs}
   - \usepackage{float}
   - \usepackage{caption}
   - \captionsetup[table]{textfont={it}, labelfont={}, singlelinecheck=false, labelsep=newline}
   - \captionsetup[figure]{textfont={}, labelfont={it}, singlelinecheck=false, labelsep=period}  
   - \usepackage{xfrac}
output: 
  pdf_document:
    latex_engine: xelatex
    highlight: zenburn
    fig_width: 6
    fig_height: 6
mainfont: "Sabon"
sansfont: "Futura"
monofont: Inconsolata    
urlcolor: "umn"
bibliography: epsy8251.bib
csl: apa-single-spaced.csl
---

\frenchspacing

<!-- LaTeX definitions -->

\mdfdefinestyle{mystyle}{userdefinedwidth=5in, align=center, backgroundcolor=yellow, roundcorner=10pt, skipabove=2em}

\mdfdefinestyle{mystyle2}{userdefinedwidth=5.5in, align=center, skipabove=10pt, topline=false, bottomline=false,
linecolor=myorange, linewidth=5pt}

\mdfdefinestyle{work}{userdefinedwidth=5in, linecolor=blue, align=center, roundcorner=10pt, skipabove=2em}


```{r knitr_init, echo=FALSE, cache=FALSE, message=FALSE}
library(knitr)
library(kableExtra)
library(rmdformats)

## Global options
options(max.print="75")
opts_chunk$set(prompt=FALSE, comment=NA, message=FALSE, warning=FALSE, tidy=FALSE, fig.width=6, fig.height=6,
               fig.pos='H', fig.align='center')
opts_knit$set(width=85)
options(scipen=5)
```


# Introduction and Research Question

In the last set of notes, we carried out an inferential analysis on the regression coefficients; testing whether the parameters were equal to zero and also computing confidence intervals to estimate the uncertainty in the coefficient estimates. In this set of notes, we will again consider statistical inference, but this time at the model level. To do so, we will again examine the question of whether time spent on homework is related to GPA using the *keith-gpa.csv* data (see the [data codebook](http://zief0002.github.io/epsy-8251/codebooks/keith-gpa.html)). To begin, we will load several libraries and import the data into an object called `keith`. 

# Preparation

```{r preparation, warning=FALSE, message=FALSE}
# Load libraries
library(broom)
library(dplyr)
library(ggplot2)
library(readr)

# Read in data
keith = read_csv(file = "~/Documents/github/epsy-8251/data/keith-gpa.csv")
head(keith)

# Fit regression model
lm.1 = lm(gpa ~ 1 + homework, data = keith)
```




Sometimes you are interested in the model as a whole, rather than the individual parameters. For example, you may be interested in whether a set of predictors *together* explains variation in the outcome. Recall that the model-level information is displayed using the `glance()` output from the **broom** package.

```{r echo=FALSE}
glance(lm.1)
```

The `r.squared` column indicates the proportion of variation in the outcome explained by differences in the predictor *in the sample*. Here, differences in time spent on homework explains 10.7\% of the variation in students' GPAs for the 100 students in the sample. 


## Model-Level Inference

The inferential question at the model level is: *Does the model explain variation in the outcome, in the population?* This can formally be expressed in a statistical hypothesis as,

$$
H_0: \rho^2 = 0
$$

To test this, we need to be able to obtain the sampling distribution of $R^2$ to estimate the uncertainty in the sample estimate. The thought experiment for this goes something like this: Imagine you have a population that is infinitely large. The observations in this population have two attributes, call them $X$ and $Y$. There is NO relationship between these two attributes; $\rho^2 = 0$. Randomly sample $n$ observations from the population. Fit the regression and compute the $R^2$ value. Repeat the process an infinite number of times.


```{r echo=FALSE, out.width='5in', fig.cap='Thought experiment for sampling samples of size n from the population to obtain the sampling distribution of R-squared.', fig.align='center', fig.pos='H'}
include_graphics("images/notes-07-thought-experiment-r2.pdf")
```



Below is a density plot of the sampling distribution for $R^2$ based on 1,000 random samples. (Not an infinite number of draws, but large enough that we should have an idea of what the distribution might look like.)

```{r fig.width=8, fig.height=6, out.width='4in', warning=FALSE, cache=TRUE, fig.cap="Sampling distribution based on 1000 simple random samples of size 32 drawn from a population where rho-squared = 0.", echo=FALSE, fig.pos='H'}
r2 = rep(NA, 1000)

for(i in 1:1000){
  y = rnorm(n = 32, mean = 0, sd = 1)
  x = rnorm(n = 32, mean = 0, sd = 1)
  r2[i] = glance(lm(y~x))$r.squared
}

ggplot(data = data.frame(r2), aes(x = r2)) +
  geom_density() +
  xlab(expression(R^2)) +
  ylab("Probability Density") +
  theme_bw()
```

This sampling distribution is right-skewed. (WHY???) This means that we cannot use a $t$-distribution to model this distribution---remember the $t$-distribution is symmetric around zero. It turns out that this sampling distribution is better modeled using an $F$-distribution.

### The F-Distribution

In theoretical statistics the $F$-distribution is the ratio of two chi-squared statistics,

$$
F = \frac{\sfrac{\chi^2_1}{\mathit{df}_1}}{\sfrac{\chi^2_2}{\mathit{df}_2}}
$$

where $\mathit{df}_1$ and $\mathit{df}_2$ are the degrees of freedom associated with each of the chi-squared statistics, respectively. For our purposes, we don't need to pay much attention to this other than to the fact that an $F$-distribution is defined using TWO parameters: $\mathit{df}_1$ and $\mathit{df}_2$. Knowing these two values completely parameterize the $F$-distribution (they give the shape, expected value, and variation).

In regression analysis, the $F$-distribution associated with model-level inference is based on the following degrees of freedom:

$$
\begin{split}
\mathit{df}_1 &= p \\
\mathit{df}_2 &= \mathit{df}_{\mathrm{Total}}-p
\end{split}
$$

where $p$ is the number of predictors used in the model and $\mathrm{Total}$ is the total degrees of freedom in the data used in the regression model ($\mathrm{Total}=n-1$). In our example, $\mathit{df}_1=1$ and $\mathit{df}_2=99-1=98$. Using these values, we have defined the $F(1,98)$-distibution.

The $F$-distribution is the sampling distribution of $F$-values (not $R^2$-values). But, it turns out that we can easily convert an $R^2$-value to an $F$-value using,

$$
F = \frac{R^2}{1 - R^2} \times \frac{\mathit{df}_2}{\mathit{df}_1}
$$

In our example,

$$
\begin{split}
F &= \frac{0.107}{1 - 0.107} \times \frac{98}{1} \\
&= 0.1198 \times 98 \\
&= 11.74
\end{split}
$$

Thus, our observed $F$-value is: $F(1,98)=11.74$. To evaluate this under the null hypothesis, we find the area under the $F(1,98)$ density curve that corresponds to $F$-values *at least as extreme* as our observed $F$-value of 11.74.

```{r echo=FALSE, out.width='3.5in', fig.cap='Plot of the probability curve for the F(1,98) distribution. The shaded area under the curve represents the p-value for a test evaluating whether the population rho-squared is zero using an observed F-value of 11.74.', fig.pos='H'}
new = data.frame(
  X = seq(from = 0, to = 20, by = 0.01)
) %>%
  rowwise() %>%
  mutate( Y = df(x = X, df1 = 1, df2 = 98) )

ggplot(data = new,  aes(x = X, y = Y)) +
  theme_bw() +
  scale_x_continuous(name = "", breaks = seq(from = 0, to = 20, by = 5)) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank()
  ) +
  geom_ribbon(data = subset(new, X >= 11.74), ymin = -10, aes(ymax = Y),
              color = "#bbbbbb", alpha = 0.4) +
  geom_line(color = "#ff7f0e") +
  geom_segment(x = 11.74, xend = 11.74, y = -10, yend = 0.1, color = "#1f77b4") +
  annotate("text", x = 11.74, y = 0.4, label = "Observed\nF-value", size = 5)
```

This area (which is one-sided in the $F$-distribution) corresponds to the $p$-value. In our case this $p$-value is 0.000885. The probability of observing an $F$-value at least as extreme as we the one we observed ($F=11.74$) under the assumption that the null hypothesis is true is 0.000885. This suggests that the empirical data are inconsistent with the hypothesis that $\rho^2=0$, and it is unlikely that the model explains no variation in students' GPAs. 

\newpage

### Using the $F$-distribution in Practice

In practice, all of this information is provided in the output of the `glance()` function.

```{r}
glance(lm.1)
```

The observed $F$-value is given in the `statistic` column and the associated degrees of freedom are provided in the `df` and `df.residual` columns. Lastly, the $p$-value is given in the `p.value` column.

## ANOVA Decomposition

We can also get the model-level inferential information from the `anova()` output. This gives us the ANOVA decomposition for the model.

```{r}
anova(lm.1)
```

Note that the two $df$ values for the model-level $F$-statistic correspond to the $df$ in each row of the ANOVA table. The first $df$ (in this case 1) is the model degrees-of-freedom, and the second $df$ (in this case 98) is the residual degrees-of-freedom. Note the $p$-value is the same as that from the `glance()` function.

This ANOVA decomposition also breaks out the sum of squared values into the variation explained by the model (616.5) and that which is unexplained by the model (residual variation; 5136.4). Summing these two values will give the total amount of variation which can be used to compute $R^2$; $R^2 = \sfrac{\mathrm{SS}_{\mathrm{Model}}}{\mathrm{SS}_{\mathrm{Total}}}$.

This decomposition also gives us another way to consider the $F$-statistic. Recall that $F$ had a direct relationship to $R^2$

$$
F = \frac{R^2}{1 - R^2} \times \frac{\mathit{df}_2}{\mathit{df}_1}
$$

Using algebra, we could also express this as a ratio of two fractions

$$
F = \frac{\frac{R^2}{\mathit{df}_1}}{\frac{1 - R^2}{\mathit{df}_2}}
$$

\newpage

Since $R^2 = \sfrac{\mathrm{SS}_{\mathrm{Model}}}{\mathrm{SS}_{\mathrm{Total}}}$ we can rewrite this as

$$
F = \frac{\frac{\mathrm{SS}_{\mathrm{Model}}}{\mathrm{SS}_{\mathrm{Total}}}}{1 - \frac{\mathrm{SS}_{\mathrm{Model}}}{\mathrm{SS}_{\mathrm{Total}}}} \times \frac{\mathit{df}_2}{\mathit{df}_1}
$$

Using simple algebra,

$$
\begin{split}
F &= \frac{\frac{\mathrm{SS}_{\mathrm{Model}}}{\mathrm{SS}_{\mathrm{Total}}}}{\frac{\mathrm{SS}_{\mathrm{Total}}}{\mathrm{SS}_{\mathrm{Total}}} - \frac{\mathrm{SS}_{\mathrm{Model}}}{\mathrm{SS}_{\mathrm{Total}}}} \times \frac{\mathit{df}_2}{\mathit{df}_1} \\[2ex]
&= \frac{\frac{\mathrm{SS}_{\mathrm{Model}}}{\mathrm{SS}_{\mathrm{Total}}}}{\frac{\mathrm{SS}_{\mathrm{Total}} - \mathrm{SS}_{\mathrm{Model}}}{\mathrm{SS}_{\mathrm{Total}}}} \times \frac{\mathit{df}_2}{\mathit{df}_1} \\[2ex]
&= \frac{\mathrm{SS}_{\mathrm{Model}}}{\mathrm{SS}_{\mathrm{Total}} - \mathrm{SS}_{\mathrm{Model}}} \times \frac{\mathit{df}_2}{\mathit{df}_1} \\[2ex]
&= \frac{\frac{\mathrm{SS}_{\mathrm{Model}}}{\mathit{df}_1}}{\frac{\mathrm{SS}_{\mathrm{Total}} - \mathrm{SS}_{\mathrm{Model}}}{\mathit{df}_2}}
\end{split}
$$

This expression of $F$ helps us see two things: $F$ is a ratio of the explained and unexplained variances, and $F$ is distributed as a ratio of two chi-squared values. 

#### F is a Ratio of the Explained and Unexplained Variances

First, the numerator is a function of the explained variation and the denominator is a function of the unexplained variation. The two degrees of freedom are also related to the model (explained) and residual/error (unexplained). In fact, $\mathit{df}_1$ is often referred to as $\mathit{df}_\mathrm{Model}$, and $\mathit{df}_2$ is often referred to as $\mathit{df}_\mathrm{Error}$. Furthermore, since $\mathrm{SS}_{\mathrm{Total}} - \mathrm{SS}_{\mathrm{Model}} = \mathrm{SS}_{\mathrm{Error}}$, $F$ is often written as

$$
F = \frac{\frac{\mathrm{SS}_{\mathrm{Model}}}{\mathit{df}_\mathrm{Model}}}{\frac{\mathrm{SS}_{\mathrm{Error}}}{\mathit{df}_\mathrm{Error}}}
$$

In statistical theory, a sum of squares divided by a degrees of freedom is referred to as a *mean squared* value---the *average* amount of variation. Thus the $F$ value here is the ratio of the average variation explained by the model and the average variation that remains unexplained. In our example

$$
\begin{split}
\mathrm{MS}_{\mathrm{Model}} &= \frac{616.5}{1} = 616.5 \\
\mathrm{MS}_{\mathrm{Error}} &= \frac{5136.4}{98} = 52.41 \\
\end{split}
$$

\newpage

These values are also printed in the `anova()` output.

```{r}
anova(lm.1)
```


The observed $F$-value of 11.76 indicates that the average explained variation is 11.76 times that of the average unexplained vartiation. There is an awful lot more explained variation than unexplained variation, on average. 

Another name for a mean squared value is a *variance estimate*; the average amount of variation (in the squared metric) is quantified as a variance. For example, go back to the introductory statistics formula for variance

$$
s^2_Y = \hat\sigma^2_Y = \frac{\sum(Y_i - \bar{Y})^2}{n-1}
$$

This numerator is a sum of squares; namely the $\mathrm{SS}_{\mathrm{Total}}$. The denomiator is the $\mathit{df}_{\mathrm{Total}}$,

$$
s^2_Y = \hat\sigma^2_Y = \frac{\mathrm{SS}_{\mathrm{Total}}}{\mathit{df}_{\mathrm{Total}}} = \mathrm{MS}_{\mathrm{Total}}
$$

Note that the $\mathrm{MS}_{\mathrm{Total}}$ is not printed in the `anova()` output. However, it can be computed from the values that are printed. The $\mathrm{SS}_{\mathrm{Total}}$ is just the sum of the printed sum of squares, and likewise the $$\mathit{df}_{\mathrm{Total}}$$ is the sum of the *df* values.

$$
\begin{split}
\mathrm{SS}_{\mathrm{Total}} &= 616.5 + 5136.4 = 5752.9 \\
\mathit{df}_{\mathrm{Total}} &= 1 + 98 = 99
\end{split}
$$

Then the $\mathrm{MS}_{\mathrm{Total}}$ is the ratio of these values,

$$
\mathrm{MS}_{\mathrm{Total}} = \frac{5752.9}{99} = 58.11
$$
Since this is a variance estimate, we could also compute the sample variance of the outcome variable, `gpa`, using the `var()` function.

```{r}
var(keith$gpa)
```

### The F-Distribution is the Ratio of Two Chi-Squared Distributions

Because mean square values are variance estimates, $F$ can also be expressed as

$$
F = \frac{\hat\sigma^2_{\mathrm{Model}}}{\hat\sigma^2_{\mathrm{Error}}}
$$

Now that we know the numerator and denominator of the $F$-value are variance estimates, we can turn to the second thing: namely that the $F$-distribution is the ratio of two $\chi^2$-distributions. Stat theory tells us that the sampling distribution for a variance is $\chi^2$-distributed with a particular *df*. The model explained variance estimate ($\hat\sigma^2_{\mathrm{Model}}$) is $\chi^2$-distributed with $\mathit{df}_{\mathrm{Total}} - p$ degrees of freedom, while the unexplained variance estimate ($\hat\sigma^2_{\mathrm{Error}}$) is $\chi^2$-distributed with $p$ degrees of freedom.


### Relationship Between Coefficient-Level and Model-Level Inference

Lastly, we point out that in simple regression models (models with only one predictor), the results of the model-level inference (i.e., the $p$-value) is exactly the same as that for the coefficient-level inference for the slope. 

```{r}
# Model-level inference
glance(lm.1)

# Coefficient-level inference
tidy(lm.1)
```


That is because the model is composed of a single predictor, so asking whether the model accounts for variation in GPA **is the same as** asking whether GPA is different, on average, for students who spend a one-hour difference in time on homework. *Once we have multiple predictors in the model, the model-level results and predictor-level results will not be the same.*


## Confidence Envelope for the Model

Re-consider our thought experiment. Again, imagine you have a population that is infinitely large. The observations in this population have two attributes, call them $X$ and $Y$. The relationship between these two attributes can be expressed via a regression equation as: $\hat{Y}=\beta_0 + \beta_1(X)$. Randomly sampe $n$ observations from the population, and compute the fitted regression equation, this time plotting the line (rather than only paying attention to the numerical estimates of the slope or intercept). Continue sampling from this population, each time drawing the fitted regression equation.



```{r echo=FALSE, out.width='5in', fig.cap='Thought experiment for sampling samples of size n from the population to obtain the fitted regression line.', fig.align='center', fig.pos='H'}
include_graphics("images/notes-07-thought-experiment-confidence-envelope.pdf")
```

Now, imagine superimposing all of these lines on the same plot. 

```{r echo=FALSE, out.width='3in', fig.cap='Plot showing the fitted regression lines for many, many random samples of size n.', fig.align='center', fig.pos='H'}
include_graphics("images/notes-07-superimposed-lines.pdf")
```

\newpage

Examining where the sampled lines fall gives a visual interpretation of the uncertainty in the model. This two-dimensional display of uncertainty is referred to as a *confidence envelope*. In practice we estimate the uncertainty from the sample data and plot it around the fitted line from the sample.

For simple regression models, we can plot this directly using the layer `stat_watercolor_smooth()` from the **educate** package. You need to install the **educate** package from syntax since it is not currently available on CRAN. To do this you need to use the `install_github()` function from the **devtools** package. The syntax to install **educate** is:

```{r eval=FALSE}
library(devtools)
install_github("zief0002/educate")
```

Once **educate** is installed and loaded we have access to the `stat_watercolor_smooth()` function. This function, which we will use as a layer in `ggplot()` will be used to create the confidence enevelope. We also include the argument `method="lm"` in this layer. Finally, we add the regression line from the observed data using `geom_abline()`.

```{r fig.width=6, fig.height=6, out.width='4in', fig.align='center', fig.pos='H', fig.cap="GPA plotted as a function of time spent on homework. The OLS regression line (black) and regression lines for 700 bootstrapped samples (blue) are also displayed."}
# Load educate library
library(educate)

# Create plot
ggplot(data = keith, aes(x = homework, y = gpa)) +
  stat_watercolor_smooth(method = "lm") +
  geom_abline(intercept = 74.3, slope = 1.21) +
  xlab("Time spent on homework") +
  ylab("GPA (on a 100-pt. scale)") +
  theme_bw()
```

\newpage

Note that the confidence envelope is made up of many different regression lines. These are lines that we could have obtained had we drawn a different sample. Because of this, sometimes this plot is referred to as a *hypothetical outcomes plot*. These lines are based on fitted lines to a set of re-sampled, or bootstrapped, data. The level of transparency gives us an indication of the uncertainty based on the observed data. More probable locations for the regression lines are darker, while less probably locations are lighter.

<!-- ## References -->


