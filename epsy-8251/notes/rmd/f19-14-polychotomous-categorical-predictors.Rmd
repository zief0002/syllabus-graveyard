---
title: "Polychotomous Categorical Predictors"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    latex_engine: xelatex
    highlight: zenburn
    fig_width: 6
    fig_height: 6
    includes: 
      in_header: preamble.tex
      before_body: doc-prefix.tex
mainfont: "Sabon"
sansfont: "Futura"
monofont: Inconsolata    
urlcolor: "umn"
bibliography: epsy8251.bib
csl: apa-single-spaced.csl
---

```{r knitr_init, echo=FALSE, cache=FALSE, message=FALSE}
library(knitr)
library(kableExtra)
library(rmdformats)

## Global options
options(max.print="75")
opts_chunk$set(prompt=FALSE, comment=NA, message=FALSE, warning=FALSE, tidy=FALSE, fig.width=6, fig.height=6,
               fig.pos='H', fig.align='center')
opts_knit$set(width=85)
options(scipen=5)
```




# Preparation

In this set of notes, we will examine the question of whether family structure affects adolescents' use of illegal substances (cigarettes, alcohol, and marijuana). In particular we will evaluate whether adolescents from intact families use these substances at different rates than adolescents from non-intact families. To do so, we will use the *substance-family.csv* data (see the [data codebook](http://zief0002.github.io/epsy-8251/codebooks/substance-family.html)). To begin, we will load several libraries and import the data into an object called `family`. 


```{r preparation, warning=FALSE, message=FALSE}
# Load libraries
library(broom)
library(corrr)
library(ggridges)
library(tidyverse)

# Import data
family = read_csv(file = "~/Documents/github/epsy-8251/data/substance-family.csv")
head(family)
```


# Examine and Describe the Marginal Distribution of the Adolescent Substance Use

To begin the analysis, we will explore the outcome variable, `substance_use`. Below we examine both the marginal distribution of this variable, and its distribution conditioned on family structure.

```{r fig.width=6, fig.height=6, out.width='3in', fig.pos='H', fig.cap="Density plot of the substance use variable.", fig.show='hold', warning=FALSE, message=FALSE}
# Marginal distribution of substance use
ggplot(data = family, aes(x = substance_use, y = ..density..)) +
  geom_histogram(color = "black", fill = "skyblue") +
  stat_density(geom = "line") +
  theme_bw() +
  xlab("Substance use") +
  ylab("Probability density")

# Substance use conditioned on family structure
ggplot(data = family, aes(x = substance_use, y = family_structure)) +
  geom_density_ridges() +
  theme_bw() +
  ylab("Family structure") +
  xlab("Substance use")
```


```{r}
# Compute summary statistics
family %>%
  group_by(family_structure) %>%
  summarize(
    M  = mean(substance_use),
    SD = sd(substance_use)
  )
```

The distribution of substance use is highly right-skewed with the majority of adolescents at the lower end of the distribution. After conditioning on family structure, the data suggest that adolescents from two-parent households have a lower mean substance use than other adolescents. Similarly, adolescents from households with one parent and one guardian have a lower mean substance use than adolescents from single-parent households. There is a great deal of variation in all three distributions and adolescents who use substances at a high rate in all three distributions. 

\newpage

# Does Family Structure Predict Adolescent Substance Use? 

To examine whether the observed difference in substance use between adolescents from the three family structures is more than we would expect because of chance, we can fit a regression model using family structure to predict variation in substance use. Before fitting this model, however, we need to create a dummy variable for EACH category of the `family_structure` variable. For our analysis, we will need to create three dummy variables: `two_parent`, `parent_guardian`, and `one_parent`. To do this we will use the `if_else()` function.

The `if_else()` function evaluates a conditional statement (which produces elements that are either `TRUE` or `FALSE`) and outputs one thing IF the element is `TRUE` and outputs something ELSE if the element is `FALSE`. The function's useage looks like this:

$$
\mathtt{if\_else(} \mathrm{conditional~statement,~output~if~TRUE,~output~if~FALSE} \mathtt{)}
$$


For example, to create the dummy variable `two_parent`, we examine the `family_structure` column and give the dummy variable a value of `1` if the label is `Two-parent family` (a `TRUE` element in our logical vector) and a value of `0` if it isn't (a `FALSE` element in our logical vector). The full `if_else()` syntax to create a `science` dummy-coded variable is this:

```{r}
# Create science dummy variable
family %>%
  mutate(
    two_parent = if_else(family_structure == "Two-parent family", 1, 0)
    )
```

Below we write the syntax to create all three dummy variables and save the new columns in the object `family`.

\vspace{1.5em}

```{r}
# Create all three dummy variables
family = family %>%
  mutate(
    two_parent = if_else(family_structure == "Two-parent family", 1, 0),
    parent_guardian = if_else(family_structure == "One-parent, one guardian", 1, 0),
    one_parent = if_else(family_structure == "Single-parent family", 1, 0),
    )

# Examine data
head(family)
```

If you do not know the actual names of the categories (or you want to check capitalization, etc.) use the `unique()` function to obtain the unique category names.

```{r}
# Get the categories
unique(family$family_structure)
```

Once the dummy variables have been created, fit the regression using all but one of the dummy variables you created. The dummy variable you leave out will correspond to the reference category. For example, in the model fitted below, we include the predictors `parent_guardian`, and `one_parent` as predictors in the model; we did not include the `two_parent` predictor. As such, adolescents from two-parent households is our reference group.

```{r}
# Two-parent households is reference group
lm.1 = lm(substance_use ~ 1 + parent_guardian + one_parent, data = family)

# Model-level info
glance(lm.1)
```

At the model-level, differences in family structure explain 1.06\% of the variation in adolescents' substance use. The empirical data are not consistent with the hypothesis that family structure does not explain variation in adolescents' substance use, $F(2,907)=4.89$, $p = .008$.

```{r}
# Coefficient-level info
tidy(lm.1)
```

The fitted regression equation is

$$
\hat{\mathrm{Substance~Use}_i} = -0.07 + 0.16(\mathrm{Parent/Guardian}_i) + 0.22(\mathrm{One\mbox{-}Parent}_i)
$$

The intercept is the average $Y$ value for the reference group. Each partial slope is the difference in average $Y$ values between the reference group and the group represented by the dummy variable. In our example,

- The average substance use for adolescents from two-parent households is $-0.07$.
- Adolescents from housholds with one parent and one guardian use substances at a rate that is 0.16 higher on average than adolescents from two-parent households.
- Adolescents from one parent housholds use substances at a rate that is 0.22 higher on average than adolescents from two-parent households.

The statistical hypothesis associated with each of the parameters in the model are:

- $H_0:\beta_0 = 0$
- $H_0:\beta_{\mathrm{Parent/Guardian}} = 0$
- $H_0:\beta_{\mathrm{One\mbox{-}Parent}} = 0$

These relate to the following scientific hypotheses:

- The average substance use for adolescents from two-parent households (reference group) is 0.
- The average substance use for adolescents housholds with one parent and one guardian is not different than the average substance use for adolescents from two-parent households.
- The average substance use for adolescents from one parent households is not different than the average substance use for adolescents from two-parent households.

Because the scientific hypotheses are really about comparisons of conditional means, the statistical hypotheses can also be written to reflect this as:

- $H_0:\mu_{\mathrm{Two\mbox{-}Parent}} = 0$
- $H_0:\mu_{\mathrm{Two\mbox{-}Parent}} = \mu_{\mathrm{Parent/Guardian}}$ or equivalently $H_0:\mu_{\mathrm{Parent/Guardian}} - \mu_{\mathrm{Two\mbox{-}Parent}} = 0$
- $H_0:\mu_{\mathrm{Two\mbox{-}Parent}} = \mu_{\mathrm{One\mbox{-}Parent}}$ or equivalently $H_0:\mu_{\mathrm{One\mbox{-}Parent}} - \mu_{\mathrm{Two\mbox{-}Parent}} = 0$

It is evaluation of the latter two hypotheses (those associated with the partial slopes in the model) that allow us to answer our research question of whether adolescents from intact families have lower rates of substance use than other adolescents. The *p*-values associated with the two partial slope coefficients indicate that the data are not consistent with the hypothesis of no difference in the rates of substance use between the reference group (two-parent households) and the family structure identified in each of the dummy coded predcitors. This implies that it is likely that the rates of substance use for both adolescents from housholds with one parent and one guardian ($t_{907}=1.76$, $p=.008$) and those from one parent housholds ($t_{907}=2.84$, $p=.005$) are higher than the substance use rate for adolescents from two-parent households.



## Omnibus Test vs. Coefficient Tests with Multiple Dummy Variables

When we use multiple dummy variables to represent a single categorical predictor, each $\beta$-term represents the mean difference between two groups. For example, in our fitted equation we see the results of testing the following two hypotheses:

$$
\begin{split}
\beta_{\mathrm{Parent/Guardian}} &= \mu_{\mathrm{Parent/Guardian}} - \mu_{\mathrm{Two\mbox{-}Parent}} \\
\beta_{\mathrm{One~Parent}} &= \mu_{\mathrm{One\mbox{-}Parent}} - \mu_{\mathrm{Two\mbox{-}Parent}} \\
\end{split}
$$

Recall that one manner in which we could write the null hypothesis associated with the model-level test is that all the partial slopes are zero. In general,

$$
H_0: \beta_1 = \beta_2 = \ldots = \beta_k = 0
$$

When we express the null hypothesis at the model-level when we use multiple dummy variables to represent a single categorical predictor, the test includes the mean differences between ALL sets of two groups, not just the differences included in the fitted equation. In our example, it represents three sets of pairwise diffeences:

- $\mu_{\mathrm{Parent/Guardian}} - \mu_{\mathrm{Two\mbox{-}Parent}}$
- $\mu_{\mathrm{One\mbox{-}Parent}} - \mu_{\mathrm{Two\mbox{-}Parent}}$
- $\mu_{\mathrm{One\mbox{-}Parent}} - \mu_{\mathrm{Parent/Guardian}}$


Thus we can express the model-level null hypothesis using partial effects as:

$$
H_0: \beta_1 = \beta_2 = \beta_3 = 0
$$

or using mean differences as:

$$
\begin{split}
H_0: &\bigg(\mu_{\mathrm{Parent/Guardian}} - \mu_{\mathrm{Two\mbox{-}Parent}}\bigg) = \bigg(\mu_{\mathrm{One\mbox{-}Parent}} - \mu_{\mathrm{Two\mbox{-}Parent}}\bigg) = \\ &\bigg(\mu_{\mathrm{One\mbox{-}Parent}} - \mu_{\mathrm{Parent/Guardian}}\bigg) = 0
\end{split}
$$

The test at the model-level is considering all three pairwise differences simultaneously. If the model-level test is significant, any one (or more than one) of the differences may not be zero. Because of this, it is important to examine ALL potential coefficient-level differences, not just those outputted from the initial fitted model.

## Evaluate Substance Use Bewteen  Adolescents from Single-Parent Households and Those from Houeholds with One Parent and One Guardian

In order to examine the remaining pairwise difference, we need to fit an additional regression model that allows us to evaluate this last comparison between adolescents from single-parent households and those from houeholds with one parent and one guardian. Below, we fit a second model (using single-parent households as the reference group) to predict variation in substance use

```{r}
# Single-parent households is reference group
lm.2 = lm(substance_use ~ 1 + parent_guardian + two_parent, data = family)

# Model-level info
glance(lm.2)
```

Note that the model-level output for this fitted model is exactly the same as that for the model in which two-parent households was the reference group. This is because we are fitting the exact same omnibus model (to examine whether the three sets of pairwise differences explain variation in substance use).

```{r}
# Coefficient-level info
tidy(lm.2)
```

The fitted regression equation, which is different than the previous fitted equation, is:

$$
\hat{\mathrm{Substance~Use}_i} = 0.16 - 0.06(\mathrm{Parent/Guardian}_i) - 0.22(\mathrm{Two\mbox{-}Parent}_i)
$$

Interpreting these values,

- The average substance use for adolescents from single-parent households is $0.16$. The empirical evidence suggests that this rate of substance use is statistically different than 0; $t_{907}=2.25$, $p=.025$.
- Adolescents from housholds with one parent and one guardian use substances at a rate that is 0.06 lower on average than adolescents from single-parent households. The empirical evidence suggests that this rate of substance use is not more than we would expect because of sampling variation; $t_{907}=-0.51$, $p=.609$.
- Adolescents from two-parent housholds use substances at a rate that is 0.22 lower on average than adolescents from two-parent households. The empirical evidence suggests that this difference in the rate of substance use is more than we would expect because of sampling variation; $t_{907}=-2.84$, $p=.005$.


### Link to the Analysis of Variance Methodology for Testing Mean Differences

Note that if all the means are equal, then each difference in the previous hypothesis would be 0. So we could also write the model-level null hypothesis as:

$$
H_0: \mu_{\mathrm{Two\mbox{-}Parent}} = \mu_{\mathrm{Parent/Guardian}} = \mu_{\mathrm{One\mbox{-}Parent}}
$$

This is the way we write the omnibus null hypothesis that is associated with the one-factor analysis of variance (ANOVA). Fitting a regression model with dummy-variables gives the exact same results as carrying out an ANOVA. The difference is that the output from the multiple regression gives $\beta$-terms associated with mean differences (to the reference group), and ANOVA is concerned more directly with the group means. But the model-level regression results are identical to those from the ANOVA. Asking whether the model explains variation in the outcome ($H_0:\rho^2=0$) is the same as asking whether there are mean differences ($H_0: \mu_{\mathrm{Two\mbox{-}Parent}} = \mu_{\mathrm{Parent/Guardian}} = \mu_{\mathrm{One\mbox{-}Parent}}$); these are just different ways of writing the model-level null hypothesis!

# Further Understanding Differences in Substance Use

If you are only interested in if there are differences in adolescent substance use between the three family structures, you can focus on the model-level (omnibus) results. If, however, you want to go further and understand the nature of those differences, in particular whether the adolescent substance use for each family structure differs from the others, it is necessary to examine the **pairwise differences** between family structures. Based on the two sets of coefficeint-level results, the pairwise differences are:

```{r echo=FALSE}
data.frame(
  comparison = c("Two-parent vs. Parent/guardian", "Two-parent vs. Single-parent", "Parent/guardian vs. Single-parent"),
  mean_diff = c("0.164", "0.221", "0.057"),
  p = c("0.079", "0.005", "0.609")
) %>%
  mutate_all(linebreak) %>%
  kable(
    col.names = linebreak(c("\nComparison", "Mean\nDifference", "\np")), 
    caption = 'Pairwise Comparisons of Adolescent Substance Use between Three Family Structures', 
    align = c("lcc"),
    format = 'latex', 
    booktabs = TRUE,
    escape = FALSE
    )  %>%
  kable_styling(latex_options = "HOLD_position")
```


## Multiple Comparisons

When we evaluated the $p$-values for each of these pairwise differences, we used an unadjusted *p*-value (the *p*-value from the `tidy()` output). This is consistent with how we have evaluated other predictors in regression models. This is okay when the regression effect constitutes a single term or mean difference in the null hypothesis. For a categorical predictor with more than two levels, however, the null hypothesis constitutes more than one mean difference.

Remember, the effect of family structure constitutes three mean differences. To be "fair" with other predictors we might include in the model that would constitute a single term/difference, we should really adjust the *p*-value to compensate for this increased number of effects/mean differences inherent in the family structure effect. There are many ways to compensate for this increased number of mean differences in the effect, and all of them adjust the *p*-value of each mean difference assoicated with family structure.


### Bonferonni Adjusted p-Values

The easeist way to make these adjustments is to multiply each *p*-value associated with the effect of family structure by 3 (the number of mean differences associated with family structure). 

$$
p_{\mathrm{Adjusted}}=p \times 3
$$

This is referred to as the Dunn-Bonferonni adjustment, named for Olvie Dunn and Carlo Bonferroni. In general, the adjustment is

$$
p_{\mathrm{Adjusted}}=p \times k,
$$

where $k$ is the number of pairwise differences encompassed in the effect. For our example,

```{r}
c(.079,.005,.609) * 3
```

In practice, since *p*-values have limits of 0 and 1, any adjusted *p*-value that exceeds 1 is limited to 1. 

```{r echo=FALSE}
data.frame(
  comparison = c("Two-parent vs. Parent/guardian", "Two-parent vs. Single-parent", "Parent/guardian vs. Single-parent"),
  mean_diff = c("0.164", "0.221", "0.057"),
  p = c("0.079", "0.005", "0.609"),
  adj_p = c("0.237", "0.015", "1.000")
) %>%
  mutate_all(linebreak) %>%
  kable(
    format = 'latex', 
    booktabs = TRUE,
    escape = FALSE,
    col.names = linebreak(c("\nComparison", "Mean\nDifference", "\np", "Bonferroni\nAdjusted p")), 
    caption = 'Pairwise Comparisons of Adolescent Substance Use between Three Family Structures', 
    align = c("lccc")
    ) %>%
  kable_styling(latex_options = "HOLD_position")
```

After adjusting the *p*-values, the difference we saw earlier in the average substance use between adolescents from two-parent housholds and those from households with one parent and one guardian, is now gone. The empirical evidence now suggests there is not a difference between these two groups. In other words, what we saw earlier was likely a type I error. The whole goal of *p*-value adjustment is to protect against type I errors!


We can adjust the *p*-values using the  Bonferroni adjustment directly with the `p.adjust()` function. To do this, we initially create a vector of the unadjusted $p$-values using the `c()` function and then include this vector in the `p.adjust()` function along with the argument `method = "bonferroni"`.

```{r}
# Create vector of unadjusted p-values
p_values = c(0.079, 0.005, 0.609)

# Bonferroni adjustment to the p-values
p.adjust(p_values, method = "bonferroni")
```

Note that the `p.adjust()` function automatically sets the upper-limit of the reported *p*-values to 1.


### Other $p$-Value Adjustment Methods

There is nothing that requires you to evenly adjust the $p$-value across the three comparisons. For example, some adjustment methods use different multipliers depending on the size of the initial unadjusted *p*-value. One of those methods is the *Benjamini--Hochberg adjustment*. This adjustment procedure ranks the unadjusted $p$-values from smallest to largest and then adjusts by the following computation\footnote{The actual adjusted $p$-value given is the minimum of this value and the adjusted $p$-value for the next higher raw $p$-value.}:

$$
p_{\mathrm{adjusted}} = \frac{k \times p_{\mathrm{unadjusted}}}{\mathrm{Rank}}
$$

In this adjustment, the numerator is equivalent to making the Bonferroni adjustment. The size of the Bonferroni adjustment is then scaled back depending on the initial rank of the unadjusted $p$-value. The smallest initial $p$-value gets the complete Bonferroni adjustment, while the largest Bonferroni adjustment is scaled back the most. We can use `method="BH"` in the `p.adjust()` function to obtain the Benjamini--Hochberg adjusted $p$-values directly.


```{r}
# Benjamini-Hochberg adjusted p-values
p.adjust(p_values, method = "BH")
```

```{r echo=FALSE}
data.frame(
  comparison = c("Two-parent vs. Parent/guardian", "Two-parent vs. Single-parent", "Parent/guardian vs. Single-parent"),
  mean_diff = c("0.164", "0.221", "0.057"),
  p = c("0.079", "0.005", "0.609"),
  adj_p = c("0.237", "0.015", "1.000"),
  adj_p2 = c("0.119", "0.015", "0.609")
) %>%
  mutate_all(linebreak) %>%
  kable(
    format = 'latex', 
    booktabs = TRUE,
    escape = FALSE,
    col.names = linebreak(c("\nComparison", "Mean\nDifference", "\np", "Bonferroni\nAdjusted p", "Benjamini--Hochberg\np")), 
    caption = 'Pairwise Comparisons of Adolescent Substance Use between Three Family Structures', 
    align = c("lcccc")
    ) %>%
  kable_styling(latex_options = "HOLD_position")
```


After adjusting the *p*-values using the Benjamini--Hochberg method, the empirical evidence suggests that only adolescents from two-parent housholds and those from single-parent households differ in their average substance use. While this is the same general result we found when we used the Bonferroni-adjusted *p*-values, the comparison between adolescents from two-parent housholds and those from households with one parent and one guardian has a much lower *p*-value using the Benjamini--Hochburg adjustment than using the Bonferroni adjustment. This suggests that the Benjamini--Hochburg adjustment provides more statistical power to find group differences than the Bonferroni adjustment.

It is importnant to note that the Benjamini--Hochburg adjustment does not protect as well against type I error as the Bonferonni adjustment does. Instead, the Benjamini--Hochburg adjustment protects against **false discovery**. In the research community, the current thinking is thatit is more beneficial to protect against false discovery than type I error, especially in exploratory research. 


### Which Adjustment Method Should I Use?

There are many, many different adjustment methods you can choose. The `p.adjust()` function, for example, includes six adjustment options (the Holm method, the Hochberg method, the Hommel method, the Bonferroni method, the Bnjamani--Hochberg method, and the Benjamini--Yekutieli method). In addition, the **multcomp** package includes several other adjustment methods.

You should decide which adjustment method you will use **before you do the analysis**. In the social sciences, the Bonferroni method has been historically the most popular method (probably because it was easy to implement before computing). That being said, I would encourage you to use the Benjamini--Hochberg adjustment method. It is from a family of adjustment methods that a growing pool of research evidence points toward as the "best" solution to the problem of multiple comparisons [@Williams:1999].  Because of its usefulness, the Institute of Education Sciences has recommended this procedure for use in its [What Works Clearinghouse Handbook of Standards](http://ies.ed.gov/ncee/wwc/Handbooks).


# Does Family Structure Predict Adolescent Substance Use After Accounting for Other Covariates? 

One question we may have is whether the differences we saw in adolescents' average substance use persist after we account for other covariates that also explain differences in substance use (e.g., sex, academic achievement). To evaluate this, we will fit a regression model that includes the `female` and `gpa` covariates along with two of the dummy-coded family structure predictors to explain variability in substance use.

```{r}
# Two-parent households is reference group
lm.3 = lm(substance_use ~ 1 + female + gpa + parent_guardian + one_parent, data = family)

# Model-level output
glance(lm.3)
```

At the model-level, differences in family structure, sex of the adolescent, and composite GPA explain 2.26\% of the variation in adolescents' substance use. The empirical data are not consis5.24$, $p < .001$.


```{r}
tidy(lm.3)
```

The fitted regression equation, which is different than the previous fitted equation, is:

$$
\hat{\mathrm{Substance~Use}_i} = 0.02 - 0.20(\mathrm{Female}_i) + 0.005(\mathrm{GPA}_i) + 0.16(\mathrm{Parent/Guardian}_i) + 0.22(\mathrm{One\mbox{-}Parent}_i)
$$

To answer our research question, we are most interested in the partial regression coefficients associated with the family structure variables. Interpreting these values,

- Adolescents from housholds with one parent and one guardian use substances at a rate that is 0.16 higher on average than adolescents from two-parent households, after controlling for differences in adolescents' sex and GPA. 
- Adolescents from one-parent housholds use substances at a rate that is 0.22 higher on average than adolescents from two-parent households. 

To determine whether there are differences in the average substance use between adolescents from one-parent households and those from households with one parent and one guardian, we need to fit an additional model with one of these groups as the reference group.

```{r}
# One-parent households is reference group
lm.4 = lm(substance_use ~ 1 + female + gpa + parent_guardian + two_parent, data = family)

tidy(lm.4)
```

- Adolescents from housholds with one parent and one guardian use substances at a rate that is 0.05 lower on average than adolescents from one-parent households, after controlling for differences in adolescents' sex and GPA. 

To evaluate whether these differences are more thanwe expect because of chance (sampling variation), we need to again adjust the *p*-values because we are evaluating three mean differences. We will do this using the Benjamini--Hochberg adjustment.

```{r}
# Create vector of unadjusted p-values
p_values = c(0.092, 0.007, 0.092)

# Bonferroni adjustment to the p-values
p.adjust(p_values, method = "BH")
```

Based on the Benjamini--Hochberg adjusted *p*-values, the only statistically relevant difference in adolescents' substance use if between those living in housholds with two-parents and those living with one-parent. The empirical evidence suggests that this difference in the rate of substance use is more than we would expect because of sampling variation; $t_{905}=2.71$, Benjamini--Hochberg adjusted $p=.021$.

The empirical evidence for the other two comparisosn are far more uncertain. Both of these differences are consistent with differences that are only due to sampling error. However, after controlling for differences in adolescents' sex and GPA, the *p*-values for both differences are much smaller than in the uncontrolled models. This might be worth noting in any write-up of the analyses.

More importantly, the effects representing the mean differences (the estimated coefficients), did not change much in magnitude nor direction. This suggests that the differences in adolescent substance use between the three family structures is stable, at least when we control for sex and GPA. Moreover, the uncertainty (as measured by the SEs) for these effects also remained stable from the uncontrolled to the controlled model. 

# Controlled Mean Differences

In the language of Analysis of Covariance (ANCOVA), the controlled mean differences are referred to as *Adjusted Mean Differences*. So, for example, the adjusted mean difference in substance use between adolescents living in two-aprent households and those living in one-parent households is 0.22 (controlling for differences in the adolescents' sex and GPA). When the mean difference is from a model that has no covariates, it is referred to as an *Unadjusted Mean Difference*. It can be useful to present both the unadjusted and adjusted mean differences in a table.

```{r echo=FALSE}
data.frame(
  comparison = c("Two-parent vs. Parent/guardian", "Two-parent vs. Single-parent", "Parent/guardian vs. Single-parent"),
  mean_diff = c("0.164", "0.221", "0.057"),
  adj_mean_diff = c("0.158", "0.210", "0.053")
) %>%
  mutate_all(linebreak) %>%
  kable(
    format = 'latex', 
    booktabs = TRUE,
    escape = FALSE,
    col.names = linebreak(c("Comparison", "Unadjusted", "Adjusted")), 
    caption = 'Unadjusted and Adjusted Mean Differences for Adolescent Substance between Three Family Structures',
    align = c("lcc")
    ) %>%
  kable_styling(latex_options = "HOLD_position") %>%
  add_header_above(c(" " = 1, "Mean Difference" = 2)) %>%
  footnote(
    general = "The adjusted mean differences were obtained by controlling for adolescent sex and GPA.",
    footnote_as_chunk = TRUE
    )
```




# Technical Appendix: Type I Error Rate andFalse-Discovery Rate

When we use an alpha value of 0.05 to evaluate consistency of the empirical data to the null hypothesis, we are saying we are willing to make a Type I error in 5\% of the samples that could be randomly selected. In other words, we will end up wrongly concluding that the empirical data are inconsistent with the null hypothesis in 5\% of the samples we would obtain from our thought experiment. (In practice, we have no idea whether our sample is one of the 5\% where we will make an error, or one of the 95\% where we won't). 

For effects that only have one row in the model, there is only one test in which we can make a Type I error ($H_0: \beta_j=0$), so we are okay evaluating each using this criterion. When we have more than two levels of a categorical predictor, there are multiple differences that constitute the effect of that predictor. To test whether there is an effect of that predictor, we evaluate *multiple hypotheis tests*. For our data, to test whether there is an effect of family strusture on substance use, we evaluate three hypothesis tests:

- $H_0:\mu_{\mathrm{Two\mbox{-}Parent}} = 0$
- $H_0:\mu_{\mathrm{Two\mbox{-}Parent}} = \mu_{\mathrm{Parent/Guardian}}$ or equivalently $H_0:\mu_{\mathrm{Parent/Guardian}} - \mu_{\mathrm{Two\mbox{-}Parent}} = 0$
- $H_0:\mu_{\mathrm{Two\mbox{-}Parent}} = \mu_{\mathrm{One\mbox{-}Parent}}$ or equivalently $H_0:\mu_{\mathrm{One\mbox{-}Parent}} - \mu_{\mathrm{Two\mbox{-}Parent}} = 0$

$$
\begin{split}
H_0: &\mu_{\mathrm{Two\mbox{-}Parent}} - \mu_{\mathrm{Parent/Guardian}} = 0 \\
H_0: &\mu_{\mathrm{Two\mbox{-}Parent}} - \mu_{\mathrm{One\mbox{-}Parent}} = 0 \\
H_0: &\mu_{\mathrm{Parent/Guardian}} - \mu_{\mathrm{One\mbox{-}Parent}} = 0
\end{split}
$$

Because of this, there are many ways to make a Type I error. For example, we could make a Type I error in any one of the three tests, or in two of the three tests, or in all three of the three tests. Therefore, the probability of making at least one Type I error is no longer 0.05, it is:

$$
P(\mathrm{type~I~error}) = 1 - (1 - \alpha)^k
$$
where $\alpha$ is the alpha level for each test, and $k$ is the number of tests (comparisons) for the effect.

<!-- \newpage -->

In our example this is

$$
P(\mathrm{type~I~error}) = 1 - (1 -0.05)^{3} = 0.142
$$

The probability that we will make *at least one Type I error* in the six tests is 0.142 NOT 0.05!!! This probability is called the family-wise Type I error rate. In the social sciences, the family-wise error rate needs to be 0.05. What should $\alpha$ be if we want the family-wise error rate to be 0.05? Essentially we would need to solve this equation:

$$
0.05 = 1 - (1 - \alpha)^{3}
$$

Carlo Emilio Bonferroni solved this algebra problem for any value of $k$ and found that the value for alpha that $\dfrac{\mathrm{family{\mbox{-}}wise~error~rate}}{k}$ gives an upper-bound for the solution. Olive Jean Dunn then used Bonferroni's solution in practice. This is why dividing by the number of comparisons is referred to as the Bonferroni or the Dunn--Bonferroni method.

\newpage

## False Discovery Rate

The Benjamini--Hochberg procedure is an ensemble method based on minimizing *false discovery rate* (FDR). FDR is a relatively new approach to the multiple comparisons problem. Instead of making adjustments to control the probability of making at least one Type I error, FDR controls the *expected proportion of discoveries* (rejected null hypotheses) when the null hypothesis is true; in other words, it controls the expected proportion of Type I error. You can find out more from [Wikipedia](https://en.wikipedia.org/wiki/False_discovery_rate).

The FDR concept was formally described in a 1995 paper by Yoav Benjamini and Yosi Hochberg, and resulted in their proposal of the Benjamini--Hochbergm method [@Benjamini:1995]. They argued that using FDR produces a less conservative and arguably more appropriate approach for identifying statistically significant comparisons.

In practice, using FDR rather than family-wise adjustment of error makes these methods less prone to over-adjustment of the $p$-values. However, the increased statistical power that comes with using the FDR methods is not without cost. They also have increased probabilities of Type I errors relative to the family-wise adjustment methods.


# References

\setlength{\parindent}{-0.2in}
\setlength{\leftskip}{0.2in}
\setlength{\parskip}{8pt}
\noindent



