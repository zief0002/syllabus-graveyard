---
title: "Multilevel Models: Longitudinal Data"
author: "Andrew Zieffler"
date: "March 29, 2016"
output: pdf_document
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Preparation

```{r message=FALSE}
# Read in the data
mplsWide = read.csv(file = "/Users/andrewz/Documents/EPsy-8252/data/minneapolis.csv")
print(head(mplsWide), row.names = FALSE)

# Load libraries
library(AICcmodavg)
library(dplyr)
library(ggplot2)
library(lme4)
library(sm)
library(tidyr)
```

# Wide Data versus Long Data

The `mplsWide` data are referred to as wide data. Wide data has the outcome variable (or predictors, or both) in multiple columns. For longitudinal data, it is convenient to enter the data into a spreadsheet in the wide format. Unfortunately, the wide format is not so good foe analysis. Functions like `lm()` or `lmer()` require data in the long format. Long formatted data has only one column for the outcome. Additionally, if there are predictors, each is in a single column as well.

There are several functions to convert data back and forth between these two formats. We will use the we will use the `gather()` function from the **tidyr** package. `gather()` takes multiple columns, and gathers them into key-value pairs. We can also use the same type of piping we use with **dplyr**. We want to have key-value pairs of time points and reading scores. You can read more about using tidyr [here](http://blog.rstudio.org/2014/07/22/introducing-tidyr/) and [here](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html).


```{r tidy=FALSE}
# Create long data from wide data (need tidyr package loaded)
mpls = mplsWide %>% gather(
  key = time, # Name of the variable that delineates the time points
  value = read, # Name of the outcome
  c(read.5, read.6, read.7, read.8) # The old variables you will use as values
  )

# Arrange by ID number
mpls = mpls %>% arrange(studentID)
head(mpls, 12)
```

The last part in our preparation is to create a numeric predictor for grade (note that currently the time predictor is a charcter vector). It is good practice to keep the character vector (or, better yet, a factor) and a numeric version of the predictor since some functions prefer one to the other. Here we use `mutate()` to create a numeric predictor called `grade`. Before we use `as.integer()` to turn the characters to numbers, however, we first turn `time` into a factor.


```{r}
# Turn time into a factor
mpls$time = as.factor(mpls$time)

# Use as.integer() to turn factor into numbers
mpls = mpls %>% mutate(grade = as.integer(time))
head(mpls)
```

Note that the way `as.integer()` works is by using the numeric information in the factor level. The first level in the time factor (after we converted it to a factor) is `read.5`. This was converted to a 1 when we used `as.integer()`; `read.6` was converted to a 2; and so on. Because grade makes sense as a number, we will add four to each value so that `read.5` will be 5; `read.6` will be 6, etc. in the new predictor.

```{r}
# Use as.integer() to turn factor into numbers
mpls = mpls %>% mutate(grade = as.integer(time) + 4)
head(mpls)
```

# Exploratory Analysis

In longitudinal data analysis we are often interested in how the outcome changes over time. Here we want to know if reading scores are changing over time. When we examine this, we typically look at the mean score across time and the variation in scores over time.

```{r tidy=FALSE}
mpls %>% 
  group_by(time) %>% 
  summarize(M = mean(read), SD = sd(read))
```

## Missingness

Since there are some students that do not have a reading score in the 8th grade, the computation of the mean and standard deviation for these grades defaulted to NA. It is typical to report both the count and percentage of missingness at each time point.

```{r tidy=FALSE}
mpls %>% 
  group_by(time) %>% 
  summarize(
    Miss = sum(is.na(read)), 
    Miss_Percent = sum(is.na(read))/length(read)
    )
```

This pattern of later time points show more missing data is quite common in longitudinal data. 

We will also compute the means and standard deviations for those students that we have data for. Below we use `filter()` to omit any NA values in the `read` variable before we do any computations.

```{r tidy=FALSE}
mpls %>% 
  filter(!is.na(read)) %>%
  group_by(time) %>% 
  summarize(M = mean(read, na.rm = TRUE), SD = sd(read))
```

The pattern in the sample data suggests that the mean reading score increases over grade level. The variation in reading scores seems fairly constant over grade levels (equal variances?). We need to be careful about the inferences coming from the last time point. The summary measures are only based on student who had data (recall 36% were missing data at grade 8). This means the estimates are likely biased.

## Correlation of Reading Scores Over Time

It is probably easiest to compute the correlation between the repeated measures using the wide formatted data. Similar to the computation of the means and standard deviations the `cor()` function will produce NAs if there is any missing data. In the function, we specify how to treat missing values. Using pairwise complet observations, the correlation between reading scores at grade 5 and grade 8, is computed only using students that have data at both time points. Because of this the correlations computed between different sets of reading scores may be based on different students. Here, `mplsWide[2:5]` indicates that the correlation matrix should be based on columns 2 through 5 (the variables read.5, read.6, read.7, read.8).

```{r}
cor(mplsWide[2:5], use = "pairwise.complete.obs")
```

The correlations show that the reading scores are correlated. They also suggest that reading scores that are further apart in time are less correlated (in statistical terms, a pattern of decay). This pattern in the correlations is also quite common in longitudinal data.

## Spaghetti Plots

A spaghetti plot is simply a plot showing the trend in the outcome over time for each person. In our case, we will be plotting the reading scores for each student. Here we are looking for the functional form for the relationship between grade level and reading score (e.g., linear, quadratic). We also add the loess smoother to better examine the functional form.

```{r tidy=FALSE, warning=FALSE, out.width='4in', out.height='4in'}
ggplot(data = mpls, aes(x = grade, y = read, group = studentID)) +
	geom_point() +
  geom_smooth(aes(group = 1), se = FALSE, lwd = 1.5) +
	geom_line(alpha = 0.3) +
	theme_bw()
```

We can also facet by student ID to show each student's pattern separately.

```{r tidy=FALSE, warning=FALSE, fig.width=12, fig.height=12, out.width='6in', out.height='6in'}
ggplot(data = mpls, aes(x = grade, y = read, group = studentID)) +
	geom_point() +
	geom_line() +
	theme_bw() +
  facet_wrap(~studentID)
```
There are three features these plots illustrate:

1. Most patterns are approximately linear (but not always) and the reading scores tend to increase over time.
2. Some OLS trajectories fit very well (e.g., Subject #7). 
3. Other OLS trajectories show more scatter (e.g., Subject #13)

However, on average, it does seem like we could model the change in reading scores over time using a linear function.

\pagebreak

# Unconditional Level-1 Model

Before we fit a linear function of time, we will first fit the unconditional level-1 model. The multilevel model for this is:

$$
\begin{split}
&\mathbf{Level\mbox{-}1~Model:~}\mathrm{Read}_i = \beta^{*}_0 + \epsilon_i \\
&\mathbf{Level\mbox{-}2~Model:~}\beta^{*}_0 = \beta_{00} + \eta_{0j}
\end{split}
$$

where $\epsilon_i\sim\mathcal{N}(0,\sigma^2_{\epsilon})$ and $\eta_{0j}\sim\mathcal{N}(0,\sigma^2_{0})$. In these models, the $i$ subscript represents a particular time point, and the $j$ subscript represents a particular person. The composite model is:

$$
\mathrm{Read}_i = \beta_{00} + \eta_{0j}+ \epsilon_i
$$

Initially we fit this model using REML estimation to get unbiased estimates of the error variances.

```{r}
lmer.0 = lmer(read ~ 1  + (1 | studentID), data = mpls)
summary(lmer.0)
```

The fitted unconditional level-1 model suggests that the mean reading score across students and grade levels is 212.2. Computing the intraclass correlation coefficient (ICC),

$$
\begin{split}
\rho &= \frac{\sigma^2_{0}}{\sigma^2_{0} + \sigma^2_{\epsilon}} \\
&= \frac{335.38}{335.38 + 66.21} \\
&= 0.83
\end{split}
$$,

we find that an estimated 83.5\% of the total variation in reading scores is attributable to differences between students, and 16.5\% of the total variation in reading scores is attributable to differences between time points (within students).

# Building the Unconditional Growth Model (Level-1 Model)

Having partitioned the total variation into within-students and between-students, we can now ask: What role does grade-level (time) play? Based on the exploratory analysis, a linear model relating grade-level and reading scores seemed appropriate. Below we show the composite model that maintains a random-effect of intercept, but also includes a linear predictor of grade-level.

$$
\mathrm{Read}_i = \beta_{00} + \beta_{10}(\mathrm{Grade}_i) + \eta_{0j}+ \epsilon_i
$$.

We also consider a quadratic effect of grade level for completeness,

$$
\mathrm{Read}_i = \beta_{00} + \beta_{10}(\mathrm{Grade}_i) + \beta_{11}(\mathrm{Grade}^2_i) + \eta_{0j}+ \epsilon_i
$$.

In both models, $\epsilon_i\sim\mathcal{N}(0,\sigma^2_{\epsilon})$ and $\eta_{0j}\sim\mathcal{N}(0,\sigma^2_{0})$. Since the error structure and random effects are the same as that for the unconditional means model, we fit this model and re-fit the unconditional means model using ML estimation. We then use AICc to select. To double-check the functional form, we also fit a quadratic model for the fixed-effects.

```{r echo=FALSE}
# Fit models using ML
lmer.0.ml = lmer(read ~ 1  + (1 | studentID), data = mpls, REML = FALSE)
lmer.1.ml = lmer(read ~ 1  + grade + (1 | studentID), data = mpls, REML = FALSE)
lmer.2.ml = lmer(read ~ 1  + grade + I(grade^2) + (1 | studentID), data = mpls, REML = FALSE)

# AICc selection
myAIC = aictab(
  cand.set = list(lmer.0.ml, lmer.1.ml, lmer.2.ml),
  modnames = c("LMER0", "LMER1", "LMER2")
)

myAIC
```

Here we adopt the model with only the linear effect of grade level.

## Graphically Examining the Level-1 Residuals: An Alternative Approach to Choosing the Level-1 Structure

Consider Student \#1's fitted models for (1) the unconditional means model, (2) the unconditional growth model (linear), and (3) the unconditional growth model (quadratic). To obtain each of these fitted models, substitute in the values of the fixed effects, and of Student \#1's random effect. (Base these on models fitted with ML.)

$$
\begin{split}
\mathbf{Model~1:~}\hat{\mathrm{Read}}_i &= 183.9 + \hat{\epsilon}_i \\
\mathbf{Model~2:~}\hat{\mathrm{Read}}_i &= 150.8 + 5.0(\mathrm{Grade}_i) + \hat{\epsilon}_i \\
\mathbf{Model~3:~}\hat{\mathrm{Read}}_i &= 131.3 + 11.3(\mathrm{Grade}_i) - 0.5(\mathrm{Grade}^2_i) + \hat{\epsilon}_i \\
\end{split}
$$

\pagebreak

Now consider the level-1 residuals for Student \#1 for each of these models.

```{r}
# Unconditional means model level-1 residuals
resid.0 = data.frame(
	studentID = lmer.0.ml@frame$studentID,
	residual = resid(lmer.0.ml),
	model = "Model 0"
	)

# Unconditional growth model (linear) level-1 residuals
resid.1 = data.frame(
	studentID = lmer.1.ml@frame$studentID,
	residual = resid(lmer.1.ml),
	model = "Model 1"
	)

# Unconditional growth model (quadratic) level-1 residuals
resid.2 = data.frame(
	studentID = lmer.2.ml@frame$studentID,
	residual = resid(lmer.2.ml),
	model = "Model 2"
	)

# Stack the three sets of residuals
all.resid = rbind(resid.0, resid.1, resid.2)

# Only Student 1
res.1 = all.resid %>% filter(studentID == 1)
res.1
```

Student \#1 has four level-1 residuals (one for each grade level) in each of the models. If the linear predictor of grade is necessary, then the residuals for the unconditional growth model (linear) should be smaller than those for the unconditional means model. Similarly, if the quadratic predictor of grade is necessary, then the residuals for the unconditional growth model (quadratic) should be smaller than those for the unconditional growth model (linear). 

\pagebreak
Below we compute the standard deviation for each model's residuals for Student \#1.

```{r}
res.1 %>% group_by(model) %>% summarize(SD = sd(residual))
```
For Student \#1, the residuals are definitely smaller in the unconditional growth model (linear) than in the unconditional means model. There doesn't seem to be any improvement in the residuals when we add the quadratic predictor. In practice, we would look at the residuals for ALL the students, not just Student \#1. Rather than computingthe standard deviation and comparing those for all the students, we just plot the residuals for each student, faceting by model. Then we can visually examine the variation.


```{r fig.width=10, fig.height=6, out.width='6in', out.height='3.6in', tidy=FALSE}
## Plot the residuals by subject ID to 
ggplot(data = all.resid, aes(x = studentID, y = residual, group = studentID)) + 
	theme_bw() +
	geom_boxplot(fill = "grey80") + 
	geom_hline(yintercept = 0) +
	facet_wrap(~ model) + 
	xlab("Subject") +
	ylab("Residual") + 
	coord_flip()
```

Adding the grade-level (time) predictor reduces the level-1 residual variation. Again, the quadratic predictor does not seem to really reduce the level-1 residual variation any further. This would suggest that a linear, but not a quadratic predictor should be included in the level-1 model.

This same information is quantified in the residual variance term. Consider the residual variance for each of the three models:

$$
\begin{split}
\mathbf{Model~0:~}\hat{\sigma}^2_{\epsilon} &= 66.2 \\
\mathbf{Model~1:~}\hat{\sigma}^2_{\epsilon} &= 29.2 \\
\mathbf{Model~2:~}\hat{\sigma}^2_{\epsilon} &= 28.9
\end{split}
$$

There is a big decrease in level-1 error variance from the unconditional means model to the unconditional growth model (linear). The residual variance from the unconditional growth model (linear) and the unconditional growth model (quadratic) are quite similar.

# Choosing Random Effects Structure

Looking back at the spaghetti plot, it seems that not only are students reading scores different at grade 0 (evidence for random intercepts), but also that their growth trajectories are different (evidence for random slopes). We will examine two different random effects structures: (1) random intercepts only; and (2) random intercepts and random slopes. Because we are keeping the fixed-effects the same, it is better to evaluate these models if we have estimated using REML.

```{r}
# Fit models using REML
lmer.1.int = lmer(read ~ 1  + grade + (1 | studentID), data = mpls)
lmer.1.both = lmer(read ~ 1  + grade + (1 + grade | studentID), data = mpls)

# AICc selection
myAIC = aictab(
  cand.set = list(lmer.1.int, lmer.1.both),
  modnames = c("Random Intercepts", "Random Intercepts + Slopes")
)

myAIC
```

The evidence supports adopting a random effects structure that includes random intercepts and random slopes.

\pagebreak

# Interpretation of the Model

```{r}
summary(lmer.1.both)
```

- The mean reading score at grade level 0 is predicted to be 181.3.
- Each grade-level difference is associated with a 4.9-point difference, on average, in reading score.
- There is still unexplained within-student residual variance (error variance is not 0). This means we can include time-varying predictors in the model (if we have any).
- There is between-student residual variance in intercepts (reading scores at grade 0) since the RE variance component is not 0.
- There is between-student residual variance in rate of change (slopes are different) since the RE variance component is not 0.
- Estimated residual correlation between intercepts and rate-of-change is negative (students who are lower than average at grade 0 tend to  grow faster than average, and vice versa)

\pagebreak

It is common to provide covariances (rather than correlations) when reporting results from LMER models. To obtain the variance--covariance matrix of the random effects, we use the `varCorr()` function. Without accessing the `studentID` component, this function would just return the RE part of the `summary()` output. 

```{r}
# Get variance-covariance matrix of the random effects
VarCorr(lmer.1.both)$studentID
```

- $\sigma^2_0 = 783.7$
- $\sigma^2_1 = 7.5$
- $\sigma_{01} = -57.3$

All three estimates should be reported in a summary or write-up of results.

# Centering a Level-1 Predictor

One thing we can do to make the intercept interpretable is to center the grade-level predictor. To do this, we will subtract five from the `grade` variable

```{r}
mpls$c.grade = mpls$grade - 5
head(mpls)  
```

Now we can re-fit the model using the centered predictor.

```{r}
lmer.1.c = lmer(read ~ 1 + c.grade  + (1 + c.grade | studentID), data = mpls)
summary(lmer.1.c)
```

- The mean reading score at grade 5 is predicted to be 205.7 (no more extrapolation).
- Each grade-level difference is associated with a 4.9-point difference, on average, in reading score (doesn't change since we didn't change the scale).

When we center predictors, the RE for the intercept and the correlation between the REs (that involve intercept) will change.

- There is still unexplained within-student residual variance (it is the same value as before).
- The intercept now pertains to students' grade 5 reading scores \ldots There is between-student residual variance in initial status (reading scores at grade 5)
- There is between-student residual variance in rate-of-change (slopes are different)
- Estimated residual correlation between initial status and rate-of-change is negative (students who are lower than average starting out at grade 5 tend to  grow faster than average, and vice versa)

Because the correlation between the RE changed, we need to re-compute the covariance estimate.

```{r}
VarCorr(lmer.1.c)$studentID 
```

- $\sigma^2_0 = 399.1$
- $\sigma^2_1 = 7.5$
- $\sigma_{01} = -19.6$






# Plotting Multilevel Models

There are two plots that you might want to consider: (1) a plot of the fixed effects model; and (2) a plot of each student's model (fixed effects + random effects). Typically we always plot the fixed effects portion of the model, since that part of the model informs us of the relationship between grade level (time) and the reading scores (outcome).

$$
\hat{\mathrm{Read}_i} = 205.7 + 4.9(\mathrm{c.grade}_i)
$$

To plot the fixed effects model, we (1) create a dataset with the appropriate predictors; (2) use the model to estimate the Y-hats; and (3) plot.

```{r out.width='4in', out.height='4in'}
# Create data set 
plotData = data.frame(
	c.grade = 0:3
	)

# The predict() function WILL NOT WORK to predict y-hats from the 
# fixed-effects model. Use fixef() function instead.
fixef(lmer.1.c)


# Compute y-hat values for the fixed-effects (average) model
# This is essentially: plotData$yhat = 205.745119 + 4.882322 * plotData$c.grade
plotData$yhat = fixef(lmer.1.c)["(Intercept)"] + fixef(lmer.1.c)["c.grade"] *  plotData$c.grade

# Examine data
plotData

# Plot
ggplot(data = plotData, aes(x = c.grade, y = yhat)) +
  geom_line() +
  theme_bw() +
  scale_x_continuous(name = "Grade", breaks = 0:3, labels = c("5", "6", "7", "8")) +
  ylab("Predicted Reading Score")
```

## Plotting the Fixed and Random Effects

The process for plotting these is similar to the previous plot. However, when we set up the initial data frame we use `expand.grid()` to include the level-2 grouping variable (`studentID`) and the predictors. An added bonus is that we can use `predict()` to get the y-hat values.

`lmer()` objects are a class of objects called S4 objects. They store output from the model in slots. To find out the names of the slots we use the `slotNames()` function.

```{r}
# What associated output do we get with an lmer() object? 
slotNames(lmer.1.c) 
```

The frame slot produces a matrix of the outcome, predictor(s), and level-2 ID for each student. This is what we need in Step 1 of the plotting process.

```{r out.width='4in', out.height='4in'}
head(lmer.1.c@frame)

# Set up the data for plotting
plotData = lmer.1.c@frame 

# Use predict() to add the y-hat values
plotData$yhat = predict(lmer.1.c, newdata = plotData)  

# Plot
ggplot(data = plotData, aes(x = c.grade, y = yhat, group = studentID)) +
	geom_line() +
  theme_bw() +
  scale_x_continuous(name = "Grade", breaks = 0:3, labels = c("5", "6", "7", "8")) +
  ylab("Predicted Reading Score")
```

# Adding Level-2 Predictors

There are several different level-2 predictors we can consider:

- Whether the student is at risk (`atRisk`) 
- Whether the student is female (`female`) 
- Whether the student is a minority student (`minority`)
- Whether the student is an English Language Learner (`ell`) 
- Whether the student is a special education student (`sped`) 
- The student's attendance rate (`att`)

In thinking about these predictors, there are several ways to proceed through the model building process. Here, I will first examine each level-2 predictor independent of the other level-2 predictors. For each level-2 predictor, we will examine (1) the unconditional growth model; (2) the unconditional growth model with the level-2 predictor for intercept only; and (3) the unconditional growth model with the level-2 predictor for intercept and slope. Since the effects that are different are the fixed effects, we fit these models using ML.

### At-Risk

```{r}
lmer.0 = lmer(read ~ 1 + c.grade + (1 + c.grade | studentID), data = mpls, REML = FALSE)
lmer.1 = lmer(read ~ 1 + c.grade + atRisk + (1 + c.grade | studentID), data = mpls, REML = FALSE)
lmer.2 = lmer(read ~ 1 + c.grade + atRisk + atRisk:c.grade + (1 + c.grade | studentID), data = mpls, REML = FALSE)

# AICc selection
myAIC = aictab(
  cand.set = list(lmer.0, lmer.1, lmer.2),
  modnames = c("Unconditional Growth", "atRisk - Intercept", "atRisk - Intercept + Slope")
)

myAIC
```

### Female

```{r}
lmer.0 = lmer(read ~ 1 + c.grade + (1 + c.grade | studentID), data = mpls, REML = FALSE)
lmer.1 = lmer(read ~ 1 + c.grade + female + (1 + c.grade | studentID), data = mpls, REML = FALSE)
lmer.2 = lmer(read ~ 1 + c.grade + female + female:c.grade + (1 + c.grade | studentID), data = mpls, REML = FALSE)

# AICc selection
myAIC = aictab(
  cand.set = list(lmer.0, lmer.1, lmer.2),
  modnames = c("Unconditional Growth", "female - Intercept", "female - Intercept + Slope")
)

myAIC
```

### Minority

```{r}
lmer.0 = lmer(read ~ 1 + c.grade + (1 + c.grade | studentID), data = mpls, REML = FALSE)
lmer.1 = lmer(read ~ 1 + c.grade + minority + (1 + c.grade | studentID), data = mpls, REML = FALSE)
lmer.2 = lmer(read ~ 1 + c.grade + minority + minority:c.grade + (1 + c.grade | studentID), data = mpls, REML = FALSE)

# AICc selection
myAIC = aictab(
  cand.set = list(lmer.0, lmer.1, lmer.2),
  modnames = c("Unconditional Growth", "minority - Intercept", "minority - Intercept + Slope")
)

myAIC
```

### English Language Learner

```{r}
lmer.0 = lmer(read ~ 1 + c.grade + (1 + c.grade | studentID), data = mpls, REML = FALSE)
lmer.1 = lmer(read ~ 1 + c.grade + ell + (1 + c.grade | studentID), data = mpls, REML = FALSE)
lmer.2 = lmer(read ~ 1 + c.grade + ell + ell:c.grade + (1 + c.grade | studentID), data = mpls, REML = FALSE)

# AICc selection
myAIC = aictab(
  cand.set = list(lmer.0, lmer.1, lmer.2),
  modnames = c("Unconditional Growth", "ell - Intercept", "ell - Intercept + Slope")
)

myAIC
```

### Special Education

```{r}
lmer.0 = lmer(read ~ 1 + c.grade + (1 + c.grade | studentID), data = mpls, REML = FALSE)
lmer.1 = lmer(read ~ 1 + c.grade + sped + (1 + c.grade | studentID), data = mpls, REML = FALSE)
lmer.2 = lmer(read ~ 1 + c.grade + sped + sped:c.grade + (1 + c.grade | studentID), data = mpls, REML = FALSE)

# AICc selection
myAIC = aictab(
  cand.set = list(lmer.0, lmer.1, lmer.2),
  modnames = c("Unconditional Growth", "sped - Intercept", "sped - Intercept + Slope")
)

myAIC
```

### Attendance

```{r}
lmer.0 = lmer(read ~ 1 + c.grade + (1 + c.grade | studentID), data = mpls, REML = FALSE)
lmer.1 = lmer(read ~ 1 + c.grade + att + (1 + c.grade | studentID), data = mpls, REML = FALSE)
lmer.2 = lmer(read ~ 1 + c.grade + att + att:c.grade + (1 + c.grade | studentID), data = mpls, REML = FALSE)

# AICc selection
myAIC = aictab(
  cand.set = list(lmer.0, lmer.1, lmer.2),
  modnames = c("Unconditional Growth", "att - Intercept", "att - Intercept + Slope")
)

myAIC
```

Based on the analyses, we should include:

- The level-2 predictor `atRisk` in the intercept model
- The level-2 predictor `minority` in the intercept model
- The level-2 predictor `att` in the intercept and slope models

Here we fit that model using REML.

```{r tidy=FALSE}
lmer.final = lmer(read ~ 1 + c.grade + atRisk + minority + att + 
      att:c.grade + (1 + c.grade | studentID), data = mpls)
summary(lmer.final)$coefficients
```

From here it is a little uncertain as to how we should proceed. The $t$-ratios for the at-risk, attendance, and attendance by grade interaction are all less than two. This suggests that maybe these terms could be dropped. Should we drop them all at once? Or one at a time? This is a good question, and there is no good answer.

Below I will proceed by dropping one term at a time, since we are taking an exploratory view of the analysis. Start by dropping the interaction term, since it is the highest order term.

```{r tidy=FALSE}
lmer.final2 = lmer(read ~ 1 + c.grade + atRisk + minority + att + 
      + (1 + c.grade | studentID), data = mpls)
summary(lmer.final2)$coefficients
```
Now we will drop the attendance main effect.

```{r tidy=FALSE}
lmer.final3 = lmer(read ~ 1 + c.grade + atRisk + minority + 
      + (1 + c.grade | studentID), data = mpls)
summary(lmer.final3)$coefficients
```
And, it looks as though the at-risk predictor can be dropped as well.

```{r tidy=FALSE}
lmer.final4 = lmer(read ~ 1 + c.grade +  minority + 
      (1 + c.grade | studentID), data = mpls)
summary(lmer.final4)$coefficients
```

# Assumption Checking

Start with the examination of the level-1 residuals.

`
out = fortify(lmer.final4)

Error in `$<-.data.frame`(`*tmp*`, ".fitted", value = c(174.501800917911,  : 
  replacement has 80 rows, data has 88
`

Unfortunately, we get an error when we try to use `fortify()`. The error is telling us that some values cannot be computed for 8 of the rows. This is because the data has 8 rows where the reading score was missing (hard to compute a residual for those rows). The solution is to drop all rows with missing data after you are in the long format, and then re-fit the final model to the data where there are no missing values. 

```{r}
# Remove missing values
mpls2 = mpls %>% na.omit()

# Re-fit model
lmer.final5 = lmer(read ~ 1 + c.grade +  minority + (1 + c.grade | studentID), data = mpls2)

# Fortify 
out = fortify(lmer.final5)
head(out)

sm.density(out$.scresid, model = "normal")

ggplot(data = out, aes(x = .fitted, y = .scresid)) +
  geom_point(size = 3) +
  theme_bw() +
  geom_hline(yintercept = 0)
```

Now we can examine the level-2 residuals for the intercept and slope. In practice, typically we only examine the normality assumptions for the level-2 residuals 

```{r}
# Compute the residuals
res0 = ranef(lmer.final5)$studentID[ , 1]
res1 = ranef(lmer.final5)$studentID[ , 2]

# Density plot of the intercept residuals
sm.density(res0, model = "normal")

# Density plot of the slope residuals
sm.density(res1, model = "normal")
```

All the assumptions seem reasonably satisfied. The last thing to do would be to produce relevant model summaries and report a reasonable taxonomy of models. Here i would report:

- The unconditional means model
- The unconditional growth model
- The "final" model with the minority level-2 predictor



