---
title: "Multilevel Models: Longitudinal Analysis"
date: "`r Sys.Date()`"
header-includes:
   - \usepackage{xcolor}
   - \usepackage[framemethod=tikz]{mdframed}
   - \usepackage{graphicx}
   - \usepackage{rotating}
   - \usepackage{booktabs}
   - \definecolor{umn}{RGB}{153, 0, 85}
   - \definecolor{umn2}{rgb}{0.1843137, 0.4509804, 0.5372549}
   - \definecolor{myorange}{HTML}{EA6153}
output: 
  pdf_document:
    highlight: tango
    latex_engine: xelatex
    fig_width: 6
    fig_height: 6
mainfont: "Bembo Std"
sansfont: "Helvetica Neue UltraLight"
monofont: Inconsolata
urlcolor: "umn2"
bibliography: epsy8252.bib
csl: apa-single-spaced.csl
always_allow_html: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(digits = 3, scipen = 99)
library(printr)
```

# Preparation

We will use datasets located in the *minneapolis.csv* file. These data include student-level attributes for $n=22$ students sampled from the Minneapolis school district. The source of these data is: @Long:2012. We will use these data to explore the longitudinal change of student reading scores.

The attributes in the *nminneapolis.csv* file include:

- `studentID`: Student ID number
- `read.5`: Student's fith-grade reading achievment score
- `read.6`: Student's sixth-grade reading achievment score
- `read.7`: Student's seventh-grade reading achievment score
- `read.8`: Student's eighth-grade reading achievment score
- `atRisk`: Is the student considered either elegible for free/reduced lunch or homeless highly mobile? (0 = no; 1 = yes)
- `female`: Is the student a female? (0 = Male; 1 = female)
- `minority`: Is the student a minority student? (0 = white student; 1 = non-white student)
- `ell`: Is the student an English language learner (ELL)? (0 = non ELL; 1 = ELL)
- `sped`: Does the student receive special education services? (0 = does not recieve special education services; 1 = recieves special education services)
- `att`: Student's attendance rate


```{r message=FALSE}
# Read in player-level and team-level data
library(readr)
mplsWide = read_csv(file = "~/Google Drive/Documents/EPsy-8252/data/minneapolis.csv")
head(mplsWide)

# Load other libraries
library(AICcmodavg)
library(broom)
library(dplyr)
library(ggplot2)
library(lme4)
library(sm)
library(tidyr)
```


# Wide Data versus Long Data

The `mplsWide` data are referred to as wide data. Wide data has the outcome variable (or predictors, or both) in multiple columns. (FUr us, the outcome we are interested in is reading achievement score.) When collecting longitudinal data, it is often convenient to enter the data into a spreadsheet in the wide format. Unfortunately, the wide format is not so good foe analysis. Functions like `lm()` or `lmer()` require that the outcome variable is in a single column; referred to as long formatted data. Additionally, if there are predictors in the data, these functions require that each predictor is also in its own (single) column.

There are several functions to convert data back and forth between these two formats. We will use the we will use the `gather()` function from the **tidyr** package. `gather()` takes multiple columns, and gathers them into key-value pairs. We can also use the same type of piping we use with **dplyr**. We want to have key-value pairs of time points and reading scores. You can read more about using tidyr [here](http://blog.rstudio.org/2014/07/22/introducing-tidyr/) and [here](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html).


```{r tidy=FALSE}
# Create long data from wide data (need tidyr package loaded)
mpls = mplsWide %>% gather(
  key = time, # Name of the variable that delineates the time points
  value = read, # Name of the outcome
  c(read.5, read.6, read.7, read.8) # The old variables you will use as values
  )

# Arrange by ID number
mpls = mpls %>% arrange(studentID)
head(mpls, 12)
```

The last part in our preparation is to create a numeric predictor for grade (note that currently the time predictor is a character vector). It is good practice to keep the character vector (or, better yet, a factor) and a numeric version of the predictor since some functions prefer one to the other. Here we use `mutate()` to create a numeric predictor called `grade`. Before we use `as.integer()` to turn the characters to numbers, however, we first turn `time` into a factor.


```{r}
# Turn time into a factor
mpls = mpls %>% mutate(time = as.factor(time))

# Use as.integer() to turn factor into numbers
mpls = mpls %>% mutate(grade = as.integer(time))
head(mpls)
```

Note that the way `as.integer()` works is by using the numeric information in the factor level. The first level in the time factor (after we converted it to a factor) is `read.5`. This was converted to a 1 when we used `as.integer()`; `read.6` was converted to a 2; and so on. Because grade makes sense as a number, we will add four to each value so that `read.5` will be 5; `read.6` will be 6, etc. in the new predictor.

```{r}
# Use as.integer() to turn factor into numbers
mpls = mpls %>% mutate(grade = as.integer(time) + 4)
head(mpls)
```

# Exploratory Analysis

In longitudinal data analysis we are often interested in how the outcome changes over time. Here we want to know if reading scores are changing over time. When we examine this, we typically look at the mean score across time and the variation in scores over time.

```{r tidy=FALSE}
mpls %>% 
  group_by(time) %>% 
  summarize(M = mean(read), SD = sd(read))
```

\newpage

## Missingness

Since there are some students that do not have a reading score in the 8th grade, the computation of the mean and standard deviation for these grades defaulted to NA. It is typical to report both the count and percentage of missingness at each time point.

```{r tidy=FALSE}
mpls %>% 
  group_by(time) %>% 
  summarize(
    Miss = sum(is.na(read)), 
    Miss_Percent = sum(is.na(read))/length(read)
    )
```

This pattern of later time points show more missing data is quite common in longitudinal data. 

We will also compute the means and standard deviations for those students that we have data for. Below we use `filter()` to omit any NA values in the `read` variable before we do any computations.

```{r tidy=FALSE}
mpls %>% 
  filter(!is.na(read)) %>%
  group_by(time) %>% 
  summarize(M = mean(read), SD = sd(read))
```

The pattern in the sample data suggests that the mean reading score increases over grade level. The variation in reading scores seems fairly constant over grade levels (equal variances?). We need to be careful about the inferences coming from the last time point. The summary measures are only based on student who had data (recall 36% were missing data at grade 8). This means the estimates are likely biased.

Another way to do this would be to use the optional argument `na.rm=TRUE` in the `mean()` and `sd()` functions. Then you wouldn't have to filter out the missing values.

```{r eval=FALSE}
mpls %>% 
  group_by(time) %>% 
  summarize(M = mean(read, na.rm = TRUE), SD = sd(read, na.rm = TRUE))
```

\newpage

## Correlation of Reading Scores Over Time

It is probably easiest to compute the correlation between the repeated measures using the wide formatted data. Similar to the computation of the means and standard deviations the `cor()` function will produce NAs if there is any missing data. In the function, we specify how to treat missing values. Using pairwise complet observations, the correlation between reading scores at grade 5 and grade 8, is computed only using students that have data at both time points. Because of this the correlations computed between different sets of reading scores may be based on different students. Here, `mplsWide[2:5]` indicates that the correlation matrix should be based on columns 2 through 5 (the variables read.5, read.6, read.7, read.8).

```{r}
cor(mplsWide[2:5], use = "pairwise.complete.obs")
```

The correlations show that the reading scores are correlated. They also suggest that reading scores that are further apart in time are less correlated (in statistical terms, a pattern of decay). This pattern in the correlations is quite common in longitudinal data.

## Spaghetti Plots

A spaghetti plot is simply a plot showing the trend in the outcome over time for each person. In our case, we will be plotting the reading scores for each student. Here we are looking for the functional form for the relationship between grade level and reading score (e.g., linear, quadratic). We also add the loess smoother to better examine the functional form.

```{r tidy=FALSE, warning=FALSE, message=FALSE, out.width='3.5in'}
ggplot(data = mpls, aes(x = grade, y = read, group = studentID)) +
	#geom_point() + 
  geom_smooth(aes(group = 1), se = FALSE, lwd = 1.5) +
	geom_line(alpha = 0.3) +
	theme_bw()
```

The loess smoother suggests that the average pattern of growth could be linear. We can examine how well this pattern holds for each student by faceting on student ID. This will to plot each student's pattern in a separate plot panel. In each panel, we also examine the fit to a linear trend.

```{r tidy=FALSE, warning=FALSE, fig.width=12, fig.height=12, out.width='6in', out.height='6in'}
ggplot(data = mpls, aes(x = grade, y = read, group = studentID)) +
	geom_point() +
	geom_line() +
  geom_smooth(aes(group = 1), se = FALSE, method = "lm") +
	theme_bw() +
  facet_wrap(~studentID)
```

There are several features these plots illustrate:

1. Most patterns are approximately linear (but not always) and the reading scores tend to increase over time.
2. Some OLS linear trajectories fit very well (e.g., Subject #7). 
3. Other OLS linear trajectories do not fit as well (e.g., Subject #13).
4. Students vary in their achievement at grade 5.
5. There is variation in the linear rate of change acorss students (i.e., the slopes vary).

\pagebreak

# Unconditional Random Intercepts Model

Before we fit a linear function of time, we will first fit the unconditional random intercepts model. The multilevel model for this is:

$$
\begin{split}
&\mathbf{Level\mbox{-}1~Model:~}\mathrm{Read}_{ij} = \beta_{0j} + \epsilon_{ij} \\
&\mathbf{Level\mbox{-}2~Model:~}\beta_{0j} = \gamma_{00} + u_{0j}
\end{split}
$$

where $\epsilon_{ij}\sim\mathcal{N}(0,\sigma^2_{\epsilon})$ and $u_{0j}\sim\mathcal{N}(0,\tau^2_{00})$. In these models, time points (level-1) are nested in students (level-2). As such, the $i$ subscript represents a particular time point, and the $j$ subscript represents a particular student. The composite model is:

$$
\mathrm{Read}_{ij} = \gamma_{00} + u_{0j}+ \epsilon_{ij}
$$

Initially we fit this model using REML estimation to get unbiased estimates of the error variances.

```{r}
lmer.0 = lmer(read ~ 1  + (1 | studentID), data = mpls)
summary(lmer.0)
```

The fitted unconditional level-1 model suggests that the mean reading score across students and grade levels is 212.2. Computing the intraclass correlation coefficient (ICC),

$$
\begin{split}
\rho &= \frac{\sigma^2_{0}}{\sigma^2_{0} + \sigma^2_{\epsilon}} \\
&= \frac{335.38}{335.38 + 66.21} \\
&= 0.83
\end{split}
$$,

we find that an estimated 83.5\% of the total variation in reading scores is attributable to differences between students, and 16.5\% of the total variation in reading scores is attributable to differences between time points (within students). 

# Building the Unconditional Growth Model (Level-1 Model)

Having partitioned the total variation into within-students and between-students, we can now ask: What role does grade-level (time) play? Based on the exploratory analysis, a linear model relating grade-level and reading scores seemed appropriate. Below are the multilevel models that include the linear effect of grade-level in the level-1 model and maintains a random-effect of intercept:

$$
\begin{split}
\mathrm{Read}_{ij} &= \beta_{0j} + \beta_{1j}(\mathrm{Grade~Level}) + \epsilon_{ij} \\
\beta_{0j} &= \gamma_{00} + u_{0j} \\
\beta_{1j} &= \gamma_{10} \\
\end{split}
$$


The composite (mixed-effects) model is:

$$
\mathrm{Read}_{ij} = \gamma_{00} + \gamma_{10}(\mathrm{Grade~Level}_{ij}) + u_{0j}+ \epsilon_{ij}
$$.

We also consider a quadratic effect of grade level for completeness (here only the composite model is shown):

$$
\mathrm{Read}_{ij} = \gamma_{00} + \gamma_{10}(\mathrm{Grade~Level}_{ij}) + \gamma_{20}(\mathrm{Grade~Level}^2_{ij}) + u_{0j}+ \epsilon_{ij}
$$.

In both models, $\epsilon_{ij}\sim\mathcal{N}(0,\sigma^2_{\epsilon})$ and $u_{0j}\sim\mathcal{N}(0,\tau^2_{00})$. Since the error structure and random effects are the same as that for the unconditional means model, we fit this model and re-fit the unconditional means model using ML estimation. We then use AICc to select the "best" level-1 structure.

```{r}
# Fit models using ML
lmer.0.ml = lmer(read ~ 1  + (1 | studentID), data = mpls, REML = FALSE)
lmer.1.ml = lmer(read ~ 1  + grade + (1 | studentID), data = mpls, REML = FALSE)
lmer.2.ml = lmer(read ~ 1  + grade + I(grade^2) + (1 | studentID), data = mpls, REML = FALSE)

# AICc selection
myAIC = aictab(
  cand.set = list(lmer.0.ml, lmer.1.ml, lmer.2.ml),
  modnames = c("Unconditional", "Grade level (L)", "Grade level (Q)")
)

myAIC
```

Here we adopt the model that includes the linear effect of grade level.

\pagebreak

## Graphically Examining the Level-1 Residuals: An Alternative Approach to Choosing the Level-1 Structure

Consider Student \#1's fitted models for (1) the unconditional means model, (2) the unconditional growth model (linear), and (3) the unconditional growth model (quadratic). To obtain each of these fitted models, substitute in the values of the fixed effects, and of Student \#1's random effect. (Base these on models fitted with ML.)

$$
\begin{split}
\mathbf{Model~1:~}\hat{\mathrm{Read}}_{ij} &= 183.9 + \hat{\epsilon}_{ij} \\
\mathbf{Model~2:~}\hat{\mathrm{Read}}_{ij} &= 150.8 + 5.0(\mathrm{Grade~Level}_{ij}) + \hat{\epsilon}_{ij} \\
\mathbf{Model~3:~}\hat{\mathrm{Read}}_{ij} &= 131.3 + 11.3(\mathrm{Grade~Level}_{ij}) - 0.5(\mathrm{Grade~Level}^2_{ij}) + \hat{\epsilon}_{ij} \\
\end{split}
$$



Now consider the level-1 residuals for Student \#1 for each of these models. To get these we are going to use the `augment()` function from the **broom** package to get the obtain the level-1 residuals from each model. We will also use `select()` to only keep the `studentID` and `.resid` columns, and `mutate()` to create a column (called `model`) that specifies the name of the model (to keep track of which model the residuals came from).

```{r}
# Unconditional means model level-1 residuals
resid.0 = augment(lmer.0.ml) %>% select(studentID, .resid) %>% mutate(model = "lmer.0")

# Unconditional growth model (linear) level-1 residuals
resid.1 = augment(lmer.1.ml) %>% select(studentID, .resid) %>% mutate(model = "lmer.1")

# Unconditional growth model (quadratic) level-1 residuals
resid.2 = augment(lmer.2.ml) %>% select(studentID, .resid) %>% mutate(model = "lmer.2")

# Stack the three sets of residuals
all.resid = rbind(resid.0, resid.1, resid.2)

# Obtain only Student 1's residuals
res.1 = all.resid %>% filter(studentID == 1)
res.1
```

Student \#1 has four level-1 residuals (one for each grade level) in each of the models. If the linear predictor of grade is necessary, then the residuals for the unconditional growth model (linear) should be smaller than those for the unconditional means model. Similarly, if the quadratic predictor of grade is necessary, then the residuals for the unconditional growth model (quadratic) should be smaller than those for the unconditional growth model (linear). 


Below we compute the standard deviation for each model's residuals for Student \#1.

```{r}
res.1 %>% group_by(model) %>% summarize(SD = sd(.resid))
```

For Student \#1, the residuals are definitely smaller in the unconditional growth model (linear) than in the unconditional means model. There doesn't seem to be any improvement in the residuals when we add the quadratic predictor. In practice, we would look at the residuals for ALL the students, not just Student \#1. Rather than computing the standard deviation and comparing those for all the students, we just plot the residuals for each student, and facet by model. Then we can visually examine the variation.


```{r fig.width=10, fig.height=6, out.width='6in', out.height='3.6in', tidy=FALSE}
## Plot the residuals by subject ID to 
ggplot(data = all.resid, aes(x = studentID, y = .resid, group = studentID)) + 
	theme_bw() +
	geom_boxplot(fill = "grey80") + 
	geom_hline(yintercept = 0) +
	facet_wrap(~ model) + 
	xlab("Student ID") +
	ylab("Level-1 Residual") + 
	coord_flip()
```

Adding the grade-level (time) predictor reduces the level-1 residual variation. Again, the quadratic predictor does not seem to really reduce the level-1 residual variation any further. This would suggest that a linear, but not a quadratic predictor should be included in the level-1 model.

This same information is quantified in the residual variance term. Consider the residual variance for each of the three models:

$$
\begin{split}
\mathbf{Model~0:~}\hat{\sigma}^2_{\epsilon} &= 66.2 \\
\mathbf{Model~1:~}\hat{\sigma}^2_{\epsilon} &= 29.2 \\
\mathbf{Model~2:~}\hat{\sigma}^2_{\epsilon} &= 28.9
\end{split}
$$

There is a big decrease in level-1 error variance from the unconditional means model to the unconditional growth model (linear). The residual variance from the unconditional growth model (linear) and the unconditional growth model (quadratic) are quite similar.

# Choosing Random Effects Structure

Looking back at the spaghetti plot, it seems that not only are students reading scores different at grade 0 (evidence for random intercepts), but also that their growth trajectories are different (evidence for random slopes). We will examine two different random effects structures: (1) random intercepts only; and (2) random intercepts and random slopes. Because we are keeping the fixed-effects the same, it is better to evaluate these models if we have estimated using REML.

```{r}
# Fit models using REML
lmer.1.int = lmer(read ~ 1  + grade + (1 | studentID), data = mpls)
lmer.1.both = lmer(read ~ 1  + grade + (1 + grade | studentID), data = mpls)

# AICc selection
myAIC = aictab(
  cand.set = list(lmer.1.int, lmer.1.both),
  modnames = c("Random Intercepts", "Random Intercepts + Slopes")
)

myAIC
```

The evidence supports adopting a random effects structure that includes random intercepts and random slopes.

\pagebreak

# Interpretation of the Model

```{r}
summary(lmer.1.both)
```

- The mean reading score at grade level 0 is predicted to be 181.3.
- Each grade-level difference is associated with a 4.9-point difference, on average, in reading score.
- There is still unexplained within-student residual variance (error variance is not 0). This means we can include time-varying predictors in the model (if we have any).
- There is between-student residual variance in intercepts (reading scores at grade 0) since the RE variance component is not 0.
- There is between-student residual variance in rate of change (slopes are different) since the RE variance component is not 0.
- Estimated residual correlation between intercepts and rate-of-change is negative (students who are lower than average at grade 0 tend to grow faster than average, and vice versa)

\pagebreak

It is common to provide covariances (rather than correlations) when reporting results from LMER models. To obtain the variance--covariance matrix of the random effects, we use the `varCorr()` function. Without accessing the `studentID` component, this function would just return the RE part of the `summary()` output. 

```{r}
# Get variance-covariance matrix of the random effects
VarCorr(lmer.1.both)$studentID
```

- $\tau^2_{00} = 783.7$
- $\tau^2_{11} = 7.5$
- $\tau_{01}   = -57.3$

All three estimates should be reported in a summary or write-up of results.

# Centering a Level-1 Predictor

One thing we can do to make the intercept interpretable is to center the grade-level predictor. To do this, we will subtract five from the `grade` variable

```{r}
mpls$c.grade = mpls$grade - 5
head(mpls)  
```

Now we can re-fit the model using the centered predictor.

```{r}
lmer.1.c = lmer(read ~ 1 + c.grade  + (1 + c.grade | studentID), data = mpls)
summary(lmer.1.c)
```

- The mean reading score at grade 5 is predicted to be 205.7 (no more extrapolation).
- Each grade-level difference is associated with a 4.9-point difference, on average, in reading score (doesn't change since we didn't change the scale).

When we center predictors, the RE for the intercept and the correlation between the REs (that involve intercept) will change.

- There is still unexplained within-student residual variance (it is the same value as before).
- The intercept now pertains to students' grade 5 reading scores \ldots There is between-student residual variance in initial status (reading scores at grade 5)
- There is between-student residual variance in rate-of-change (slopes are different)
- Estimated residual correlation between initial status and rate-of-change is negative (students who are lower than average starting out at grade 5 tend to  grow faster than average, and vice versa)

Because the correlation between the RE changed, we need to re-compute the covariance estimate.

```{r}
VarCorr(lmer.1.c)$studentID 
```

- $\tau^2_{00} = 399.1$
- $\tau^2_{11} = 7.5$
- $\tau_{01}  = -19.6$


# Plotting Results from Longitudinal Models

There are two plots that you might want to consider: (1) a plot of the fixed-effects model; and (2) a plot of each student's model (fixed-effects + random-effects). Typically we always plot the fixed-effects portion of the model, since that part of the model informs us of the relationship between grade level (time) and the reading scores (outcome).

$$
\hat{\mathrm{Read}_{ij}} = 205.7 + 4.9(\mathrm{c.grade}_{ij})
$$

To plot the fixed effects model, we (1) create a dataset with the appropriate predictors; (2) use the model to estimate the $y$-hat values; and (3) plot.

```{r out.width='3.5in'}
# Create data set 
plotData = expand.grid(
	c.grade = 0:3
	)

# Compute y-hat values for the fixed-effects (average) model
plotData$yhat = predict(lmer.1.c, newdata = plotData, re.form = NA)
head(plotData)

# Plot
ggplot(data = plotData, aes(x = c.grade, y = yhat)) +
  geom_line() +
  theme_bw() +
  scale_x_continuous(name = "Grade level", breaks = 0:3, labels = c("5", "6", "7", "8")) +
  ylab("Predicted reading score")
```

\pagebreak

## Plotting the Fixed- and Random-Effects

The process for plotting these is similar to plotting the fixed-effects. However, when we set up the initial data frame we also include the level-2 grouping variable (`studentID`) in `expand.grid()` along with any predictors. When we estimate $y$-hat values using the `predict()` function, we do not include the `re.form=` argument. Finally, when we plot, we group according to student ID so that we plot a different line for each student (i.e., random effects of intercept and slope). We can add the average line by including a second `geom_line()` layer drawing from the previous `plotData` object.



```{r out.width='3.5in'}
# Create data set 
student_data = expand.grid(
	c.grade = 0:3,
	studentID = 1:22
	)

# Use predict() to add the y-hat values
student_data$yhat = predict(lmer.1.c, newdata = student_data)  

# Plot
ggplot(data = student_data, aes(x = c.grade, y = yhat, group = studentID)) +
	geom_line(alpha = 0.3) +
  geom_line(data = plotData, aes(x = c.grade, y = yhat, group = 1), color = "blue", lwd = 1.5) +
  theme_bw() +
  scale_x_continuous(name = "Grade level", breaks = 0:3, labels = c("5", "6", "7", "8")) +
  ylab("Predicted reading score")
```

\pagebreak

# Adding Level-2 Predictors

There are several different level-2 predictors we can consider:

- Whether the student is at risk (`atRisk`) 
- Whether the student is female (`female`) 
- Whether the student is a minority student (`minority`)
- Whether the student is an English Language Learner (`ell`) 
- Whether the student is a special education student (`sped`) 
- The student's attendance rate (`att`)

In thinking about these predictors, there are several ways to proceed through the model building process. Here, I will first examine each level-2 predictor independent of the other level-2 predictors. For each level-2 predictor, we will examine (1) the unconditional growth model; (2) the unconditional growth model with the level-2 predictor for intercept only; and (3) the unconditional growth model with the level-2 predictor for intercept and slope. Since the effects that are different are the fixed effects, we fit these models using ML. (Note that although the multilevel and composite models are not expressed in these notes, it is good practice to write these out as you are learning multilevel analysis.)

### At-Risk

```{r}
lmer.0 = lmer(read ~ 1 + c.grade + (1 + c.grade | studentID), data = mpls, REML = FALSE)
lmer.1 = lmer(read ~ 1 + c.grade + atRisk + (1 + c.grade | studentID), data = mpls, REML = FALSE)
lmer.2 = lmer(read ~ 1 + c.grade + atRisk + atRisk:c.grade + (1 + c.grade | studentID), data = mpls, REML = FALSE)

# AICc selection
myAIC = aictab(
  cand.set = list(lmer.0, lmer.1, lmer.2),
  modnames = c("Unconditional Growth", "atRisk - Intercept", "atRisk - Intercept + Slope")
)

myAIC
```

### Female

```{r}
lmer.0 = lmer(read ~ 1 + c.grade + (1 + c.grade | studentID), data = mpls, REML = FALSE)
lmer.1 = lmer(read ~ 1 + c.grade + female + (1 + c.grade | studentID), data = mpls, REML = FALSE)
lmer.2 = lmer(read ~ 1 + c.grade + female + female:c.grade + (1 + c.grade | studentID), data = mpls, REML = FALSE)

# AICc selection
myAIC = aictab(
  cand.set = list(lmer.0, lmer.1, lmer.2),
  modnames = c("Unconditional Growth", "female - Intercept", "female - Intercept + Slope")
)

myAIC
```

### Minority

```{r}
lmer.0 = lmer(read ~ 1 + c.grade + (1 + c.grade | studentID), data = mpls, REML = FALSE)
lmer.1 = lmer(read ~ 1 + c.grade + minority + (1 + c.grade | studentID), data = mpls, REML = FALSE)
lmer.2 = lmer(read ~ 1 + c.grade + minority + minority:c.grade + (1 + c.grade | studentID), data = mpls, REML = FALSE)

# AICc selection
myAIC = aictab(
  cand.set = list(lmer.0, lmer.1, lmer.2),
  modnames = c("Unconditional Growth", "minority - Intercept", "minority - Intercept + Slope")
)

myAIC
```

### English Language Learner

```{r}
lmer.0 = lmer(read ~ 1 + c.grade + (1 + c.grade | studentID), data = mpls, REML = FALSE)
lmer.1 = lmer(read ~ 1 + c.grade + ell + (1 + c.grade | studentID), data = mpls, REML = FALSE)
lmer.2 = lmer(read ~ 1 + c.grade + ell + ell:c.grade + (1 + c.grade | studentID), data = mpls, REML = FALSE)

# AICc selection
myAIC = aictab(
  cand.set = list(lmer.0, lmer.1, lmer.2),
  modnames = c("Unconditional Growth", "ell - Intercept", "ell - Intercept + Slope")
)

myAIC
```

### Special Education

```{r}
lmer.0 = lmer(read ~ 1 + c.grade + (1 + c.grade | studentID), data = mpls, REML = FALSE)
lmer.1 = lmer(read ~ 1 + c.grade + sped + (1 + c.grade | studentID), data = mpls, REML = FALSE)
lmer.2 = lmer(read ~ 1 + c.grade + sped + sped:c.grade + (1 + c.grade | studentID), data = mpls, REML = FALSE)

# AICc selection
myAIC = aictab(
  cand.set = list(lmer.0, lmer.1, lmer.2),
  modnames = c("Unconditional Growth", "sped - Intercept", "sped - Intercept + Slope")
)

myAIC
```

### Attendance

```{r}
lmer.0 = lmer(read ~ 1 + c.grade + (1 + c.grade | studentID), data = mpls, REML = FALSE)
lmer.1 = lmer(read ~ 1 + c.grade + att + (1 + c.grade | studentID), data = mpls, REML = FALSE)
lmer.2 = lmer(read ~ 1 + c.grade + att + att:c.grade + (1 + c.grade | studentID), data = mpls, REML = FALSE)

# AICc selection
myAIC = aictab(
  cand.set = list(lmer.0, lmer.1, lmer.2),
  modnames = c("Unconditional Growth", "att - Intercept", "att - Intercept + Slope")
)

myAIC
```

Based on the analyses, we should include:

- The level-2 predictor `atRisk` in the intercept model
- The level-2 predictor `minority` in the intercept model
- The level-2 predictor `att` in the intercept and slope models

Here we fit that model using REML.

```{r tidy=FALSE}
lmer.final = lmer(read ~ 1 + c.grade + atRisk + minority + att + 
      att:c.grade + (1 + c.grade | studentID), data = mpls)
summary(lmer.final)$coefficients
```


From here it is a little uncertain as to how we should proceed. The $t$-ratios for the at-risk, attendance, and attendance by grade interaction are all less than two. This suggests that maybe these terms could be dropped. To examine this, it is worth fitting a series of models that drops those terms (starting with the interaction term and then the main-effects, starting with the lowest $t$-value).  

```{r tidy=FALSE}
# Drop att:time interaction term
lmer.final2 = lmer(read ~ 1 + c.grade + atRisk + minority + att + 
      + (1 + c.grade | studentID), data = mpls)

# Drop att:time and att main-effect
lmer.final3 = lmer(read ~ 1 + c.grade + atRisk + minority + 
      + (1 + c.grade | studentID), data = mpls)

# Drop att:time and att and atRisk main-effects
lmer.final4 = lmer(read ~ 1 + c.grade +  minority + 
      (1 + c.grade | studentID), data = mpls)
```

Now we will compute AICc information for these four models.

```{r}
# AICc selection
myAIC = aictab(
  cand.set = list(lmer.final, lmer.final2, lmer.final3, lmer.final4),
  modnames = c("Full model", "-att:c.grade", "-att:c.grade, -att", "-att:c.grade, -att, -atRisk")
)

myAIC
```

Using infomation criteria, we would adopt the model that includes the fixed-effects of time, attendance, at-risk, minority and the interaction between time and attendance.


# Assumption Checking

Start with the examination of the level-1 residuals.

```{r out.width='3.5in'}
out = augment(lmer.final)
#head(out)

# Normality of level-1 residuals
sm.density(out$.resid, model = "normal", xlab = "Level-1 residuals")
```

The assumption that the level-1 residuals are normally distributed looks satisfied. Next we will check the linearity and homogeneity of variance assumptions for the level-1 residuals.


```{r out.width='3.5in'}
ggplot(data = out, aes(x = .fitted, y = .resid)) +
  geom_point(size = 3) +
  theme_bw() +
  geom_hline(yintercept = 0) +
  xlab("Fitted values") +
  ylab("Level-1 residuals")
```


Both of those assumptions also look reasonably satisfied. Now we can examine the level-2 residuals for the intercept and slope. In practice, typically we only examine the normality assumptions for the level-2 residuals. 


```{r eval=FALSE}
# Compute the residuals
u0 = ranef(lmer.final)$studentID[ , 1]
u1 = ranef(lmer.final)$studentID[ , 2]

# Density plot of the intercept residuals
sm.density(u0, model = "normal", xlab = "Level-2 residuals (intercept)")

# Density plot of the slope residuals
sm.density(u1, model = "normal", xlab = "Level-2 residuals (slope)")
```

```{r fig.width=8, fig.height=4, out.width='5in', echo=FALSE}
# Compute the residuals
u0 = ranef(lmer.final)$studentID[ , 1]
u1 = ranef(lmer.final)$studentID[ , 2]


par(mfrow = c(1, 2))
sm.density(u0, model = "normal", xlab = "Level-2 residuals (intercept)")
sm.density(u1, model = "normal", xlab = "Level-2 residuals (slope)")
par(mfrow = c(1, 1))
```

All the assumptions seem reasonably satisfied. The last thing to do would be to produce relevant model summaries and report a reasonable taxonomy of models. Here I would report:

- The unconditional means model
- The unconditional growth model
- The "final" model with the minority level-2 predictor

\pagebreak

```{r message=FALSE, eval=FALSE, echo=FALSE}
library(texreg)

lmer.1 = lmer(read ~ 1 + (1 | studentID), data = mpls)

lmer.2 = lmer(read ~ 1 + c.grade  + (1 + c.grade | studentID), data = mpls)

lmer.3 = lmer(read ~ 1 + c.grade + atRisk + minority + att + 
      att:c.grade + (1 + c.grade | studentID), data = mpls)


tr1 = extract.lmerMod(lmer.1, include.nobs = FALSE)
tr2 = extract.lmerMod(lmer.2, include.nobs = FALSE)
tr3 = extract.lmerMod(lmer.3, include.nobs = FALSE)
  
texreg(list(tr1,tr2,tr3), custom.coef.names = c("Intercept", "Grade level", "At-risk", "Minority", "Attendance rate", "Grade level x Attendance rate"), reorder.coef = c(2, 3, 4, 5, 6, 1))
```

\begin{table}
\begin{center}
\begin{tabular}{l c c c }
\hline \\[5pt]
 & Model A & Model B & Model C \\
\hline\\[-3pt]
\multicolumn{4}{c}{\textit{Fixed-effects}}\\[5pt]
Grade level                        &                & $4.88^{***}$   & $-30.21$       \\
                                   &                & $(0.76)$       & $(18.53)$      \\
At-risk                            &                &                & $-12.74$       \\
                                   &                &                & $(7.90)$       \\
Minority                           &                &                & $-22.36^{**}$  \\
                                   &                &                & $(7.98)$       \\
Attendance rate                    &                &                & $-126.17$      \\
                                   &                &                & $(103.73)$     \\
Grade level x Attendance rate      &                &                & $36.69$        \\
                                   &                &                & $(19.35)$      \\
Intercept                          & $212.24^{***}$ & $205.75^{***}$ & $346.57^{***}$ \\
                                   & $(4.01)$       & $(4.33)$       & $(102.30)$     \\
\hline\\[-3pt]
\multicolumn{4}{c}{\textit{Variance estimates}}\\[5pt]
Student (Intercept)         & 335.38         & 399.12         & 209.73         \\
Student (Grade level)             &                & 7.55           & 6.90           \\
Covariance &                & -19.59         & -4.07          \\
Residual                      & 66.21          & 18.30          & 17.74          \\
\hline\\[-3pt]
\multicolumn{4}{c}{\textit{Goodness-of-Fit}}\\[5pt]
AICc                                & 628         & 579        & 541         \\
\hline
\multicolumn{4}{l}{\scriptsize{$^{***}p<0.001$, $^{**}p<0.01$, $^*p<0.05$}}
\end{tabular}
\caption{Statistical models}
\label{table:coefficients}
\end{center}
\end{table}

*Table 1.* Coefficients (Standard Errors) for a Taxonomy of Fitted Multilevel Models to Predict 5th--8th Grade Reading Achievement Scores for $n=22$ Students. Results are Reported Based on Fitting Each Model using Restricted Maximum Likelihood Estimation.

Since there is an interaction term, we should plot the model results to help interpret the fixed-effects of grade level and attendance rate. However the other estimated fixed-effects in the model can be interpreted:

- The mean reading achievement score for white, non at-risk students with a 0% attendance rate (extrapolation) at grade 5 is predicted to be 346.6.
- In the 5th grade, students who are at-risk are predicted to have a mean reading achievement scores that is 12.7 points lower then students who are not at-risk, controlling for differences in attendance rate and minority status.
- In the 5th grade, minority students are predicted to have a mean reading achievement scores that is 22.4 points lower then white students, controlling for differences in attendance rate and whether or not they are at-risk.

\pagebreak 

To interpret the effects of grade level and attendance rate, we would probably want to plot the fixed-effects of the adopted model. 

```{r fig.width=12, fig.height=10, out.width='5in'}
# Create data set
fixed_effects = expand.grid(
	c.grade = 0:3,
	att = c(0.85, 0.95),
	atRisk = c(0, 1),
	minority = c(0, 1)
	)

# Use predict() to add the y-hat values
fixed_effects$yhat = predict(lmer.final, newdata = fixed_effects, re.form = NA)  

# Coerce any predictors not on the x-axis into factors for better plotting
fixed_effects$att = factor(fixed_effects$att, levels = c(0.85, 0.95), 
                               labels = c("85% attendance rate", "95% attendance rate"))

fixed_effects$atRisk = factor(fixed_effects$atRisk, levels = c(0, 1), 
                               labels = c("Non at-risk students", "At-risk students"))

fixed_effects$minority = factor(fixed_effects$minority, levels = c(0, 1), 
                               labels = c("White students", "Minority students"))


# Plot
ggplot(data = fixed_effects, aes(x = c.grade, y = yhat, color = att)) +
	geom_line() +
  theme_bw() +
  scale_x_continuous(name = "Grade level", breaks = 0:3, labels = c("5", "6", "7", "8")) +
  ylab("Predicted reading score") +
  facet_grid(minority ~ atRisk) +
  scale_color_brewer(name = "Attendance rate", palette = "Set1")
```

This plot displays the positive linear effect of grade level on reading achievement scores (for all groups of students). The magnitude of the grade level effect, however, is different depending on attendance rate. In general, the effect of grade level on reading achievement score is higher for students who have higher attendance rates, controlling for differences in risk and minority status.


# References
