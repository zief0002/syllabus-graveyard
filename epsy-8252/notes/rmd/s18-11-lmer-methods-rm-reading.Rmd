---
title: "Longitudinal LMER Models: Reading Example"
output: html_notebook
---

```{r message=FALSE}
library(AICcmodavg)
library(corrr)
library(dplyr)
library(ggplot2)
library(lme4)
library(readr)
library(texreg)
library(tidyr)
```

In this example we are going to look at a small dataset of students' reading scores measures over time. These data are in the `reading-wide.csv` file.

```{r message=FALSE}
reading_wide = read_csv(file = "~/Dropbox/epsy-8252/data/reading-wide.csv")
reading_wide
```

The data contains 5th, 6th, 7th, and 8th-grade reading scores for 22 students. We also have a dummy variable, `atRisk` that indicates whether the student is at-risk (free/reduced-price lunch or homeless/high mobility student).

## Prepare Data for Analysis

We will first convert the data to the long (tidy) format.

```{r}
reading_long = reading_wide %>%
  gather(key = "grade_cat", value = "read_score", read.5:read.8) %>%
  arrange(studentID, grade_cat)

reading_long
```

We will also convert the categorical grade predictor to a numeric variable indicating grade. Because it is useful to include 0 in the data, we will center the numeric variable at 5th grade (i.e., 5th grade = 0).

```{r}
# Map year_cat to continuous years
lookup_table = tibble(
  grade_cat = c("read.5", "read.6", "read.7", "read.8"),
  grade = c(0, 1, 2, 3)
)

# Join the data
reading = left_join(reading_long, lookup_table, by = "grade_cat")
reading
```

## Explore the Data

We begin by doing a cursory examination of the data.

```{r}
summary(reading)
```

This indicates that the outcome variable (`read_score`) has some cases with missing values. Looking through the data, we see these are all measurements at 8th grade. To compute summary measures, we need to drop all the cases from our long data that have missing values.

```{r}
reading = reading %>%
  drop_na()
```

Note: ONLY DROP CASES WITH MISSING VALUES AFTER THE DATA IS IN THE LONG FORMAT!!!

Now we compute summary measures.

```{r}
# Compute means and SDs by year
read_summaries = reading %>%
  group_by(grade) %>%
  summarize(
    M = mean(read_score),
    SD = sd(read_score)
  )

read_summaries
```

We can also plot the mean values over time.

```{r}
ggplot(data = reading, aes(x = grade, y = read_score)) +
  geom_line(aes(group = studentID), alpha = 0.3) +
  geom_line(data = read_summaries, aes(x = grade, y = M), size = 1.5, color = "blue") +
  geom_point(data = read_summaries, aes(x = grade, y = M), size = 3, color = "blue") +
  theme_bw() +
  xlab("Grade (centered at 5th grade)") +
  ylab("Reading score")

```

The spaghetti plot and summary statistics suggest:

- The mean reading score changes over time. It seems to be increasing.
- The variation in reading scores at each time point appears to be homogenous.
- The mean growth profile appears to be linear in nature.
- Individual students seem to have 5th grade reading scores (intercepts) that vary from the mean reading score at 5th grade.
- Students' individual growth profiles look linear, and in general, follow the same trajetory as the mean growth profile.

## Modeling the Mean Growth Profile (Fixed-Effect of Grade)

To begin our longitudinal analysis, we will explore a series of models that include a series of fixed-effects that allow us to determine the functional form of the fixed-effect (average) model. All of these models will include a random-effect of intercept to account for the dependency in the data due to repeated measurements.

```{r}
# Unconditional means model
lmer.0 = lmer(read_score ~ 1 + (1|studentID), data = reading, REML = FALSE)

# Linear growth model
lmer.1 = lmer(read_score ~ 1 + grade + (1|studentID), data = reading, REML = FALSE)

# Quadratic growth model
lmer.2 = lmer(read_score ~ 1 + grade + I(grade^2) + (1|studentID), data = reading, REML = FALSE)

# Likelihood ratio tests
anova(lmer.0, lmer.1, lmer.2)
```

The likelihood ratio tests indicate:

- The linear growth model (`lmer.1`) fit better than the unconditional means model (`lmer.0`), $\chi^2(1)=47.22$, $p < .001$.
- The quadratic growth model (`lmer.2`) does not fit better than the linear growth model, $\chi^2(1)=0.62$, $p = .433$.

This suggests that we should adopt a fixed-effect of intercept and grade in our model.

## Modeling Random-Effects

After we settle on the fixed-effects of time, we next turn our attention to the random-effects that need to be included. We will include a random-effect of intercept for sure (to account for the dependence among repeated measures). But, we could also include a random-effect of grade. That would say that individual students could have different 5th grade reading scores from the average intercept (random-effect of intercept) and they could have different linear growth than the average profile (random-effect of slope).

To examine this we will use the AICc values. We cannot use the likelihood ratio test to test random-effects; despite the fact that the random-intercepts model is nested in the random-intercepts-and-slopes model. The LRT is only accurate for testing differences in the fixed-effects part of the model.

```{r}
lmer.1 = lmer(read_score ~ 1 + grade + (1|studentID), data = reading, REML = FALSE)
lmer.3 = lmer(read_score ~ 1 + grade + (1 + grade|studentID), data = reading, REML = FALSE)

# Table of model evidence
aictab(
  cand.set = list(lmer.1, lmer.3),
  modnames = c("Linear growth model", "Linear growth model (RE = Linear slopes)")
  )
```

The model evidence suggests that our model should include random-effects for both intercept and slope.

### Understanding the Model's Output

```{r}
summary(lmer.3)
```

The estimated fixed-effects are similar to our unconditional growth model, and are interpreted in the same manner:

- The predicted average reading score in 5th grade for students is 205.7.
- On average, at each subsequent grade-level, students increase their reading score by 4.88.

There are now three variance components:

- $\hat\sigma^2_{\epsilon}=18.315$ This represents the unexplained within-student variation.
- $\hat\sigma^2_{b_0}=380.59$ This represents the unexplained between-student variation in intercepts (5th grade reading scores).
- $\hat\sigma^2_{b_1}=6.97$ This represents the unexplained between-student variation in slopes (growth profiles).

There is also another model parameter that is not shown in the output that we should report; the covariance between the random-effects of intercept and the random-effect for slopes. To obtain this, we use the `VarCorr()` function.

```{r}
VarCorr(lmer.3)$studentID
```

The top part of this output gives us a *variance--covariance* matrix of the random-effects, often referred to as **G**. (Matrices are bolded.) In mathematical notation,

$$
\mathbf{G} = \begin{bmatrix} 380.59 & -18.57 \\ -18.57 & 6.97 \end{bmatrix}
$$

Along the main-diagonal of this matrix are the variance estimates for the intercept and slope random-effects, respectively. The off-diagonal elements are the covariances between the random-effects. We denote a covariance as $\sigma$. For our estimated model,

$$
\hat\sigma_{b_{0},b_{1}} = -18.57
$$

Remember that a covariance is an unstandardized correlation. We typically don't interpret covariances, other than their sign. IN our case this is negative. This means that:

- Students who have a random-effect of intercept that is positive tend to have a random-effect of slope that is negative.

In other words,

- Students who have a 5th grade reading score that is above the average 5th grade reading score tend to have a growth rate that is less than the average growth rate, and vice-versa.

The functions in `texreg()` will automatically report the covariance values, along with the variance components, in their output.

```{r results='asis'}
htmlreg(list(lmer.3), 
        stars = NULL, doctype = FALSE,
        caption = "Results of a Linear Mixed-Effects Model to Explain Variation in Student's Reading Scores", caption.above = TRUE)
```



## Exploring Covariates: Adding Fixed-Effects

Once we have settled on a fixed-effects structure for time and the random-effects structure, we can begin adding covariates to the model. Covariates are added to the fixed-effect part of the model only. However, these effects can be main-effects or interactions with time.

The covariate we have is `atRisk`. We can start by computing the mean reading scores over time for both the at-risk and non-at-risk students to see if there are differences.

```{r}
atrisk_summaries = reading %>%
  group_by(grade, atRisk) %>%
  summarize(
    M = mean(read_score),
    SD = sd(read_score)
  ) %>%
  arrange(atRisk, grade)

atrisk_summaries
```

We can also examine a spaghetti plot, where we have colored the profiles based on the student's risk status. We also plot the mean reading scores to show the average profile for both sets of students.


```{r}
ggplot(data = reading, aes(x = grade, y = read_score, color = factor(atRisk))) +
  geom_line(aes(group = studentID), alpha = 0.4) +
  geom_line(data = atrisk_summaries, aes(x = grade, y = M, color = factor(atRisk)),
            size = 1.5) +
  geom_point(data = atrisk_summaries, aes(x = grade, y = M, color = factor(atRisk)),
            size = 3) +
  theme_bw() +
  xlab("Grade (centered at 5th grade)") +
  ylab("Reading score") +
  scale_color_manual(name = "Risk status", values = c("red", "blue")) +
  facet_wrap(~factor(atRisk))
```

This exploration indicates:

- The average 5th grade reading score for at-risk students is lower than the average 5th grade reading score for not-at-risk students.
- The average growth profile for at-risk students is similar to the average profile for not-at-risk students; both are linear with similar slopes.

Since the two lines show a difference in 5th grade scores (also seen in the means), we can include a main-effect of `atRisk` in the model. To test whether the lines are truly parallel, we can also examine a model that includes and interaction between time and `atRisk`. Since these effects are fixed-effects, we can use a LRT to examine these different models.

```{r}
# No covariates
lmer.3 = lmer(read_score ~ 1 + grade + (1 + grade|studentID), 
              data = reading, REML = FALSE)

# Main-effect of risk
lmer.4 = lmer(read_score ~ 1 + grade + atRisk + (1 + grade|studentID), 
              data = reading, REML = FALSE)

# Interaction-effect of risk:grade
lmer.5 = lmer(read_score ~ 1 + grade + atRisk + atRisk:grade + (1 + grade|studentID), 
              data = reading, REML = FALSE)

# Likelihood ratio tests
anova(lmer.3, lmer.4, lmer.5)
```

The likelihood ratio tests indicate:

- The model that includes the main-effects of risk and time (`lmer.4`) fit better than the model that only includes the effect of time (`lmer.3`), $\chi^2(1)=7.79$, $p = .005$.
- The model that includes the interaction-effect between risk and time (`lmer.5`) does not fit better than the model that includes only the main-effects of risk and time, $\chi^2(1)=0.14$, $p = .705$.

This suggests that we should adopt a model that includes:

- Fixed-effects of intercept, grade, and risk
- Random-effects of intercept and grade

## Writing the Fitted Equation of the Adopted Model

```{r}
summary(lmer.4)
```

The fitted equation of the fixed-effects model is:

$$
\hat{\mathrm{Read}_{ij}}=216.87 + 4.88(\mathrm{Grade}_{ij}) - 20.40(\mathrm{Risk}_j)
$$

To interpret these effects:

- The predicted average reading score in 5th grade for students who are not at-risk is 216.87.
- On average, at each subsequent grade-level, students increase their reading score by 4.88, controlling for differences in rsik status.
- On average, students who are at-risk have reading scores that are 20.40 point lower than their peers who are not at-risk, controlling for differences in grade-level.


## Plot of the Fixed-Effects Model

It can be beneficial to plot these results.

```{r}
plot_data = expand.grid(
  grade = seq(from = 0, to = 3, by = 1),
  atRisk = c(0, 1)
  ) %>%
  mutate(
    yhat = predict(lmer.4, newdata = ., re.form = NA)
  ) %>%
  mutate(
    atRisk = factor(atRisk, levels = c(0, 1), labels = c("Not at-risk", "At-risk"))
  )



ggplot(data = plot_data, aes(x = grade, y = yhat, color = atRisk)) +
  geom_line() +
  theme_bw() +
  xlab("Grade (centered at 5th grade") +
  ylab("Reading score") +
  scale_color_manual(name = "Risk status", values = c("red", "blue"))
```


## Show an Individual Student's Growth Profile

Let's examine Student 02. To obtain Student 02's fitted equation we need to combine the fixed-effects estimates with Student 02's estimated random-effects.

```{r}
ranef(lmer.4)
```

Student 02's random-effects are:

- $\hat{b_{0j}}$ = 5.12
- $\hat{b_{1j}}$ = $-0.26$

We can write Student 02's fitted model as:


$$
\begin{split}
\hat{\mathrm{Read}_{ij}} &= \bigg[216.87 + 5.12\bigg] + \bigg[4.88-0.26\bigg](\mathrm{Grade}_{ij}) - 20.40(\mathrm{Risk}_j) \\
&= 221.99 + 4.62(\mathrm{Grade}_{ij}) - 20.40(\mathrm{Risk}_j)
\end{split}
$$

We also know that Student 02 is at-risk (`atRisk` = 1). We can substitue this value into the equation to get the fitted-equation for this student's growth profile.

$$
\begin{split}
\hat{\mathrm{Read}_{ij}} &= 221.99 + 4.62(\mathrm{Grade}_{ij}) - 20.40(1) \\
&= 242.39 + 4.62(\mathrm{Grade}_{ij})
\end{split}
$$

Student 02's fitted equation suggests:

- Student 02's model predicted 5th grade reading score is 242.39
- On average, at each subsequent grade-level, Student 02 increases her/his/their reading score by 4.62.

To plot this student's growht profile, we will set up a new dataset to predict from the includes Student 02's data. We also include this student's ID value. When we predict, we omit the argument `re.form = NA`. This predicts from the model that includes BOTH the fixed- and random-effects. 

```{r}
student_02 = expand.grid(
  grade = seq(from = 0, to = 3, by = 1),
  atRisk = 1,
  studentID = 2
  ) %>%
  mutate(
    yhat = predict(lmer.4, newdata = .)
  )

student_02
```

To add this to our existing plot of the fixed-effects, we include another `geom_line()` layer and within that layer set the `data=` and aesthetics to map to our Student 02 data set. We also color this profile the same color as the at-risk average growth profile.

```{r}
ggplot(data = plot_data, aes(x = grade, y = yhat, color = atRisk)) +
  geom_line() +
  theme_bw() +
  xlab("Grade (centered at 5th grade") +
  ylab("Reading score") +
  scale_color_manual(name = "Risk status", values = c("red", "blue")) +
  geom_line(data = student_02, aes(x = grade, y = yhat), color = "blue", linetype = "dotted")
```


## Regression Table

We can present a selected taxonomy of models in a regression table. Below, I include the:

- Unconditional means model (as a baseline model, this should always be included);
- Adopted model for fixed-effect(s) of time (for us, a linear growth model);
- Adopted model for the random-effect(s) structure (Re of both intercept and grade);
- "Final" model with any covariates

```{r results='asis'}
htmlreg(list(lmer.0, lmer.1, lmer.3, lmer.4), 
        stars = NULL, doctype = FALSE,
        caption = "Taxonomy of Linear Mixed-Effects Models to Explain Variation in Student's Reading Scores", caption.above = TRUE)
```

<br />




