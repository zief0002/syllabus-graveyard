---
title: "Assumptions Underlying LMER Models"
date: "`r Sys.Date()`"
header-includes:
   - \usepackage{xcolor}
   - \usepackage[framemethod=tikz]{mdframed}
   - \usepackage{graphicx}
   - \usepackage{rotating}
   - \usepackage{booktabs}
   - \usepackage{xfrac}
   - \usepackage{array}
   - \usepackage{tabularx}
   - \renewcommand\tabularxcolumn[1]{m{#1}}  
   - \definecolor{umn}{RGB}{153, 0, 85}
   - \definecolor{umn2}{rgb}{0.1843137, 0.4509804, 0.5372549}
   - \definecolor{myorange}{HTML}{EA6153}
output: 
  pdf_document:
    highlight: tango
    latex_engine: xelatex
    fig_width: 6
    fig_height: 6
mainfont: "Bembo Std"
sansfont: "Helvetica Neue UltraLight"
monofont: Inconsolata
urlcolor: "umn2"
always_allow_html: yes
bibliography: epsy8282.bib
csl: apa-single-spaced.csl
nocite: | 
  @Singer:2003, @Long:2012, @Loy:2014
---






The general model for the linear mixed-effects model is:

$$
\mathbf{Y_i} = \mathbf{X_i}\boldsymbol{\beta} + \mathbf{Z_i}\mathbf{b_i} + \boldsymbol{\epsilon_i}
$$

where

$$
\begin{split}
\boldsymbol{\epsilon_{ij}} &\overset{i.i.d}{\sim} \mathcal{N}\big( 0, \sigma^2_{\epsilon}\big) \\[1em]
\mathbf{b_i} &\sim \mathcal{N}\big(\mathbf{0}, \mathbf{G}  \big)
\end{split}
$$


For the linear mixed-effects model with a linear fixed-effect of time and random-effects of both intercept and slope, the model would be:

$$
Y_{ij} = \beta_0 + \beta_1(\mathrm{Time_{ij}}) + b_0 + b_1(\mathrm{Time_{ij}}) + \epsilon_{ij}
$$


$$
\begin{split}
\boldsymbol{\epsilon_{ij}} &\sim \mathcal{N}\big( 0, \sigma^2_{\epsilon}\big) \\[1em]
\begin{bmatrix}b_{0i} \\ b_{1i} \end{bmatrix} &\sim \mathcal{N}\bigg(\begin{bmatrix}0 \\ 0 \end{bmatrix}, \bigg(\begin{bmatrix}\sigma^2_0 & \sigma_{01} \\ \sigma_{10} & \sigma^2_1 \end{bmatrix} \bigg)
\end{split}
$$

These assumptions state that:

- The level-1 errors are normally distributed. 
- The level-1 errors are independent of one another.
- The level-1 errors have a mean of 0 (linearity).
- The level-1 errors and have constant variance.
- All random-effects (intercept and slope) are normally distributed.
- All random-effects (intercept and slope) have mean of zero (linearity). 
- There is a variance for each of the random-effects and a covariance between them.

Any time a model is fitted we need to evaluate these assumptions to ensure the validity of any results we interpret from the model.


## Example: Vocabulary Data

Consider again the vocabulary data that we used in previous notes. (The importing and preparation of these data is not shown.) Here we fit the model that includes a fixed-effect of grade and random-effects of both intercept and slope to the data.

```{r setup, echo=FALSE, warning=FALSE, message=FALSE}
# Load libraries
library(tidyverse)
library(lme4)
library(stringr)

# Read in wide data
vocab = read_csv(file = "~/Dropbox/epsy-8282/data/vocab.csv")

# Convert to long data
vocab_long = vocab %>% 
  gather(time, score, t8:t11) %>%
  mutate(
    grade = as.integer(str_replace(time, pattern = "t", replacement = "")) - 8
    ) %>%
  select(id, grade, score, female) %>%
  arrange(id, grade) 

# Fit mixed-effects model
lmer.1 = lmer(score ~ 1 + grade + (1 + grade | id), data = vocab_long, REML = FALSE)
```

\newpage

We can use the `augment()` function from the **broom** package to obtain the fitted-values and level-1 residuals from an LMER model.

```{r message=FALSE, warning=FALSE}
library(broom)

# AUgment the model to obtain residuals
out1 = augment(lmer.1)
head(out1)
```

In this output, the `.fitted` values are the predicted vocabulary scores based on the fixed- and random-effects. The `.mu` values are the predicted vocabulary scores based on the fixed-effects only. The `.resid` values are the residuals based on the difference between the observed vocabulary scores and the `.fitted` values (the level-1 errors).

To evaluate the assumptions, we will look afor similar patterns in the residual plots that we do when we are evaluating the assumptions from a fixed-effects regression (however, we look at a slightly different set of plots to do this). Since we will need to look at the random-effects, it is useful to put the random-effects in a data frame for easy access in the plot syntax.

```{r}
# Put RE in data frame
r_effects = ranef(lmer.1)$id 

# Change the name of the first column from "(Intercept)" to "Intercept"
names(r_effects)[1] = "Intercept"

# Add ID (row number) to the data frame
r_effects = r_effects %>% mutate(ID = as.integer(row.names(r_effects)))

# Inspect the data frame
head(r_effects)
```


\newpage

## Normality of the Level-1 Residuals and the Random Effects

```{r eval=FALSE}
# Load sm library
library(sm)

# Level-1 residuals
sm.density(out1$.resid, model = "normal", xlab = "Level-1 residuals")

# Random effect of intercept
sm.density(r_effects$Intercept, model = "normal", xlab = "Intercept random-effect")

# Random effect of slope
sm.density(r_effects$grade, model = "normal", xlab = "Linear slope random-effect")
```


```{r fig.width=9, fig.height=3, out.width='6in', echo=FALSE, message=FALSE}
library(sm)


par(mfrow = c(1, 3))

# Level-1 residuals
sm.density(out1$.resid, model = "normal", xlab = "Level-1 residuals")

# Random effect of intercept
sm.density(ranef(lmer.1)$id[1], model = "normal", xlab = "Intercept random-effect")

# Random effect of slope
sm.density(ranef(lmer.1)$id[2], model = "normal", xlab = "Linear slope random-effect")
par(mfrow = c(1, 1))
```

*Figure 1.* Density plots of the level-1 residuals (left), intercept random-effects (middle), and linear slope random-effects (right). The plots indicate that the normality assumptions are all tenable. 

\vspace{2em}

None of the three distributions show evidence that the normality assumption has been violated. The observed distributions all lie within the confidence band consistent with random sampling from a normal distribution. We would probably indicate that the assumptions about normality are reasonably satisfied for this model.


The right-hand side of the density plots of the random-effects maybe suggests some small deviation from normality (where the observed curve does not lie within the confidence band). Looking for these observations in the output of the random-effects, we find that it is a single observation (Row 36) that is deviating in both plots. 

```{r echo=FALSE}
r_effects %>% filter(Intercept > 5)
```

If we were concerned about this deviation, we could remove the observation, re-fit the model, and the re-check the asumptions. For now, I will leave the observation in, and check the other assumptions.

## Linearity

The "linearity" assumption is about the growth trajectory for each individual. In a residual plot, checking this is about examining that the mean level-1 residual for each person is zero (random scatetr around the line $y=0$). 

```{r fig.width=6, fig.height=6, out.width='3in', message=FALSE}
ggplot(data = out1, aes(x = id, y = .resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  theme_bw()
```

*Figure 2.* Plot of the level-1 residuals versus the ID values. The plot shows random scatter around the $y=0$ line. The empirical loess smoother also shows little deviation from the $y=0$ line. 

\vspace{2em}

The evidence from the residual plot of the level-1 residuals versus the ID values suggests that the linearity assumption is tenable and the mean residual for all individuals is zero.


```{r fig.width=8, fig.height=4, out.width='6in', message=FALSE}
p1 = ggplot(data = r_effects, aes(x = ID, y = Intercept)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  theme_bw()

p2 = ggplot(data = r_effects, aes(x = ID, y = grade)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  theme_bw()

gridExtra::grid.arrange(p1, p2, nrow = 1)
```

*Figure 3.* Plot of the random-effects versus the ID values. The intercept random-effects (left) and the linear slope random-effects (right) suggest that the linearity assumption is tenable. 

\vspace{2em}

The evidence from these two plots suggestst that the linearity assumption for the random-effects is tenable. The plots, in general, both show random scatter around the $y=0$ line. The empirical loess smoother also shows little deviation from the $y=0$ line. ID=36 again shows up as an extreme residual in these plots. This is where the loess smoother seems to deviate most from the $y=0$ line.

### Scaling Residuals and Random-Effects

Just like in fixed-effects regression, standardizing the residuals from the mixed-effects models can help us better identify outlying observations. To standardize the level-1 residuals we used the `resid()` function with the argument `scaled=TRUE`. Here we add a column of scaled residuals to the augmented data frame.

```{r fig.width=6, fig.height=6, out.width='3in', message=FALSE}
# Add column of scaled level-1 residuals
out1 = out1 %>%
  mutate( scl_resid = resid(lmer.1, scaled = TRUE))

head(out1)

# Plot of the scaled level-1 residuals vs. ID
ggplot(data = out1, aes(x = id, y = scl_resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  theme_bw()
```

*Figure 4.* Plot of the scaled level-1 residuals versus the ID values. 

\vspace{2em}

Evaluating the assumption about linearity, we draw the EXACT same conclusion from this plot as we did from the plot using the unscaled residuals. Now, however, it is easier for us to say whether there are EXTREME residuals since the scale on the $y$-axis is now in standard errors. In this plot there does not appear to be any observations with extreme level-1 residuals.

To standardize the random-effects, we will divide the random-effects by the respective standard deviation of the RE. These can be obtained from the `summary()` output. 

```{r}
# Obtain the scaled REs
r_effects = r_effects %>%
  mutate(
    scl_intercept = Intercept / 1.771334,
    scl_grade = grade / 0.946748
  )

head(r_effects)
```

\newpage

```{r fig.width=8, fig.height=4, out.width='6in', message=FALSE}
p1 = ggplot(data = r_effects, aes(x = ID, y = scl_intercept)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  theme_bw()

p2 = ggplot(data = r_effects, aes(x = ID, y = scl_grade)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  theme_bw()

gridExtra::grid.arrange(p1, p2, nrow = 1)
```

*Figure 5.* Plot of the scaled random-effects versus the ID values. Observation 36 seems to have an extremely high random-effect of intercept. 

\vspace{2em}

The random-effect of intercept for observation 36 now, indeed, looks to be extreme; it is almost four standard errors higher than we would expect. Again, we will hold off on removing this observation, although the evidence is starting to build to this decision.

### Plots of the Residuals and Random-Effects versus the Predictors

We should also (1) plot the level-1 residuals versus each of the predictors in the level-1 model (grade) and (2) plot each of the random-effects versus each of the predictors in the respective level-2 models. Here we will also use the scaled residuals and random-effects.

```{r fig.width=6, fig.height=6, out.width='3in', message=FALSE, warning=FALSE}
# Plot scaled level-1 residuals vs. predictor in level-1 model
ggplot(data = out1, aes(x = grade, y = scl_resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  theme_bw()
```

*Figure 6.* Plot of the scaled level-1 residuals versus grade. 

\vspace{2em}

There are no level-2 predictors, so we don't need to examine any plots for the REs here.

## Constant Variance

To evaluate the constant variance assumptions, we will use the same plots we used to evaluate linearity. For the most part, in all of these plots, it seems that the constant variance assumption is satisfied. The exception might be in the plots of the random-effects where ID=36 seems to have more variation because of its large RE relative to the others.

## Remove Observation 36

Here we will remove observation 36 from the data and re-fit the model. Then, we can re-evaluate the assumptions based on the re-estimated REs and residuals.

```{r}
# Create new data set that removes ID=36
vocab_long_2 = vocab_long %>%
  filter(id != 36)

lmer.2 = lmer(score ~ 1 + grade + (1 + grade | id), data = vocab_long_2, REML = FALSE)
```

Now we will examine the same set of plots. The plots below are based on the scaled residuals and scaled random-effects. (Below I show the syntax to obtain the scaled residuals, bu not the syntax to create the plots. This syntax would essentially be identical to previous syntax.) Here when we are adding the ID column to the random-effects data frame, we need to 

```{r message=FALSE}
# Level-1 residuals
out2 = augment(lmer.2) %>%
  mutate( scl_resid = resid(lmer.2, scaled = TRUE))

# Random-effects
r_effects = ranef(lmer.2)$id 

# Change column name for Intercept
names(r_effects)[1] = "Intercept"

# Add ID column and scaled REs
r_effects = r_effects %>% 
  mutate(ID = as.integer(row.names(r_effects))) %>%
  mutate(
    scl_intercept = Intercept / 1.541329,
    scl_grade = grade / 0.953593
  )

head(r_effects)
```

```{r fig.width=9, fig.height=3, out.width='6in', echo=FALSE, message=FALSE}
par(mfrow = c(1, 3))
sm.density(out2$.resid, model = "normal", xlab = "Level-1 residuals")
sm.density(r_effects$Intercept, model = "normal", xlab = "Intercept random-effect")
sm.density(r_effects$grade, model = "normal", xlab = "Linear slope random-effect")
par(mfrow = c(1, 1))
```

*Figure 7.* Density plots of the level-1 residuals (left), intercept random-effects (middle), and linear slope random-effects (right). The plots indicate that the normality assumptions are all tenable. 

\vspace{2em}


```{r fig.width=12, fig.height=6, out.width='6in', message=FALSE, warning=FALSE}
# Plot of the scaled level-1 residuals vs. ID
p1 = ggplot(data = out2, aes(x = id, y = scl_resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  theme_bw() +
  ggtitle("Scaled Level-1 Residuals vs. ID")

p2 = ggplot(data = out2, aes(x = grade, y = scl_resid)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  theme_bw() +
  ggtitle("Scaled Level-1 Residuals vs. Grade")

gridExtra::grid.arrange(p1, p2, nrow = 1)
```

*Figure 8.* Plot of the scaled level-1 residuals versus ID value (left) and grade (right). The plots suggest that the assumptions of linearity and constant variance are both tenable. 

\vspace{2em}

```{r fig.width=12, fig.height=6, out.width='6in', message=FALSE, warning=FALSE}
p1 = ggplot(data = r_effects, aes(x = ID, y = scl_intercept)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  theme_bw() +
  ggtitle("Scaled RE of Intercept vs. ID")

p2 = ggplot(data = r_effects, aes(x = ID, y = scl_grade)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE) +
  theme_bw() +
  ggtitle("Scaled RE of Grade vs. ID")

gridExtra::grid.arrange(p1, p2, nrow = 1)
```

*Figure 9.* Plot of the scaled random-effects versus ID. The plots suggest that the assumption of linearity and constant variance are both tenable. The loess line does indicate some departure from linearity, even after removing Observation 36. 

\vspace{2em}

Here are the results from both models. (Note that we cannot use AIC or BIC to compare these models since they were fitted to different data sets.)

```{r echo=FALSE, eval=FALSE}
library(stargazer)
stargazer(lmer.1, lmer.2)
```

\vspace{2em}

Table 1.

*Results from Fitting a Mixed-Effects Regression Model to Predict Vocabulary Scores Over Time. Coefficient Estimates, (Standard Errors), and t-Values are Presented.*


\begin{table}[!htbp] 
\begin{tabular}{@{\extracolsep{5pt}}m{3cm}m{3cm}m{3cm}} 
\\[2ex]\hline 
  & All \par Obs. \par $(N=256)$ & Removing \par Obs. 36 \par $(N=252)$ \\
\hline \\[-1.8ex] 
 Grade & 0.747 & 0.746 \\ 
  & (0.053) & (0.054) \\
  & 14.11 & 13.89 \\
  & & \\ 
 Constant & 1.413 & 1.301 \\ 
  & (0.243) & (0.219) \\
  & 5.83 & 5.95 \\
\hline \\[-1.8ex] 
\end{tabular} 
\end{table} 


Removing the observations from ID=36 does not change the results much. In both sets of results, we would find an effect of grade on vocabulary scores. Since removing the observations associated with ID 36 does not seem to improve the residual fit of the model assumptions that much, it seems like we might be better reporting the results from the full data set.


## Example 2: Model that Includes Sex as a Covariate

Consider if we had included the main-effect of gender into our model, the multi-level models for this are:

$$
\begin{split}
\mathrm{Vocab}_{ij} &= \beta^{*}_{0} + \beta^{*}_{1}\big(\mathrm{Grade}_{ij}\big) + \epsilon_{ij} \\[1em]
\beta^{*}_{0} &= \beta_{00} + \beta_{01}\big(\mathrm{Female}_{i}\big) + b_{0i}\\
\beta^{*}_{1} &= \beta_{10} + b_{1i}
\end{split}
$$

In this model, when we are evaluating the assumptions, we would look at:

- Density plot of the level-1 scaled residuals
- Density plot of the scaled intercept random-effects
- Density plot of the scaled linear grade random-effects
- Scatterplot of the level-1 scaled residuals versus the IDs
- Scatterplot of the scaled intercept random-effects versus the IDs
- Scatterplot of the scaled linear grade random-effects versus the IDs
- Scatterplot of the level-1 scaled residuals versus the grade
- Scatterplot of the scaled intercept random-effects versus female

Since we have included a level-2 predictor in the intercept equation, we would also evaluate the residuals of that model (the RE of the intercept) versus the included predictors from that model.

If we had included the main-effect of gender and the interaction between gender and grade into our model, the multi-level models are:

$$
\begin{split}
\mathrm{Vocab}_{ij} &= \beta^{*}_{0} + \beta^{*}_{1}\big(\mathrm{Grade}_{ij}\big) + \epsilon_{ij} \\[1em]
\beta^{*}_{0} &= \beta_{00} + \beta_{01}\big(\mathrm{Female}_{i}\big) + b_{0i}\\
\beta^{*}_{1} &= \beta_{10} + \beta_{11}\big(\mathrm{Female}_{i}\big) +b_{1i}
\end{split}
$$

In this model, when we are evaluating the assumptions, we would look at:

- Density plot of the level-1 scaled residuals
- Density plot of the scaled intercept random-effects
- Density plot of the scaled linear grade random-effects
- Scatterplot of the level-1 scaled residuals versus the IDs
- Scatterplot of the scaled intercept random-effects versus the IDs
- Scatterplot of the scaled linear grade random-effects versus the IDs
- Scatterplot of the level-1 scaled residuals versus the grade
- Scatterplot of the scaled intercept random-effects versus female
- Scatterplot of the scaled linear grade random-effects versus female


<!-- ## Residuals as Criteria for Selecting Models -->

<!-- We can also evaluate whether we should include predictors by comparing the residuals across models. For example, below, we will plot the level-1 residuals for three models: (1) Unconditional means model, (2) Linear change model, and (3) Quadratic change model. All three models will include only the random-effect of intercept.  -->

<!-- ```{r} -->
<!-- # Fit model w/main effect of gender -->
<!-- lmer.0 = lmer(score ~ 1 +                      (1 | id), data = vocab_long, REML = FALSE) -->
<!-- lmer.1 = lmer(score ~ 1 + grade +              (1 | id), data = vocab_long, REML = FALSE) -->
<!-- lmer.2 = lmer(score ~ 1 + grade + I(grade^2) + (1 | id), data = vocab_long, REML = FALSE) -->
<!-- ``` -->

<!-- To compare these models I augment each model to get the level-1 residuals. Then I add the model name to each of the augmented data sets and select only the ID, residual, and model name columns. Finally I stack the three data sets into  single data set and plot the residuals by ID, facetting on model. -->

<!-- ```{r fig.width=12, fig.height=9, out.width='6in', message=FALSE, warning=FALSE} -->
<!-- # Augment models, add model name, select ID, residuals and model name -->
<!-- out0 = augment(lmer.0) %>% mutate(model = "lmer.0") %>% select(id, .resid, model) -->
<!-- out1 = augment(lmer.1) %>% mutate(model = "lmer.1") %>% select(id, .resid, model) -->
<!-- out2 = augment(lmer.2) %>% mutate(model = "lmer.2") %>% select(id, .resid, model) -->

<!-- # Stack the three datasets -->
<!-- all_three = rbind(out0, out1, out2) -->
<!-- head(all_three) -->

<!-- # Plot -->
<!-- ggplot(data = all_three, aes(x = id, y = .resid)) + -->
<!--   geom_point() + -->
<!--   geom_hline(yintercept = 0) + -->
<!--   geom_smooth(se = FALSE) + -->
<!--   theme_bw() + -->
<!--   #coord_flip() + -->
<!--   facet_wrap(~model, ncol = 1) -->
<!-- ``` -->

<!-- *Figure 10.* Plot of the level-1 residuals versus ID for three candidate models.  -->

<!-- \vspace{2em} -->

<!-- From this plot we can see that the residuals for lmer.1 are smaller than those for lmer.0 (in general). This is evidence that adding the linear fixed-effect of grade improves the residual fit from the intercept-only model. Including a quadratic fixed-effect of grade only slightly improves the residual fit beyond the linear model.  -->

<!-- If we look at the confidence set for the three models, the evidence supports the quadratic model. Remember the evidence used here is the AICc values (and the $\Delta$AICc values). This is based on the deviance values which comes out of computing the log-likelihood. This is a different criteria than just using the residuals. -->


<!-- ```{r} -->
<!-- library(AICcmodavg) -->

<!-- confset( -->
<!--   cand.set = list(lmer.0, lmer.1, lmer.2), -->
<!--   modnames = c("lmer.0", "lmer.1", "lmer.2"), -->
<!--   method = "ordinal" -->
<!--   ) -->
<!-- ``` -->


## References


